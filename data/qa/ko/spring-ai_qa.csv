"Spring AI 프로젝트는 어떤 목적을 가지고 있나요?","Spring AI 프로젝트는 인공지능 기능을 불필요한 복잡성 없이 통합하는 애플리케이션 개발을 간소화하는 것을 목표로 합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/index.html)"
"Spring AI 프로젝트는 어떤 프로그래밍 언어에 초점을 맞추고 있나요?","Spring AI 프로젝트는 Python뿐만 아니라 다양한 프로그래밍 언어에서 사용할 수 있는 범용적인 AI 애플리케이션을 개발하기 위해 만들어졌습니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/index.html)"
"Spring AI는 어떤 종류의 AI 모델과 데이터베이스를 지원하나요?","Spring AI는 OpenAI, Microsoft, Amazon, Google, Hugging Face와 같은 주요 모델 제공업체와 Apache Cassandra, Azure Vector Search, Chroma, Milvus, MongoDB Atlas, Neo4j, Oracle, PostgreSQL/PGVector, PineCone, Qdrant, Redis, Weaviate와 같은 주요 벡터 데이터베이스 제공업체를 지원합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/index.html)"
"Spring AI에서 지원하는 모델은 어떤 종류가 있나요?","Spring AI는 언어, 이미지, 오디오를 입력 및 출력으로 처리하는 모델을 지원합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/concepts.html)"
"프롬프트란 무엇이며, AI 모델에서 어떤 역할을 하나요?","프롬프트는 AI 모델을 특정 출력을 생성하도록 안내하는 언어 기반 입력의 기반이 됩니다. 효과적인 프롬프트를 작성하는 것은 예술과 과학의 결합입니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/concepts.html)"
"임베딩이란 무엇이며, AI 모델에서 어떻게 사용되나요?","임베딩은 입력 간의 관계를 포착하는 텍스트, 이미지 또는 비디오의 수치 표현입니다. 임베딩은 AI 모델이 관련 개념을 인식하고 그룹화하는 데 도움이 됩니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/concepts.html)"
"스프링 AI를 사용하기 위해 추천하는 방법은 무엇인가요?","스프링 AI를 사용하기 위해 먼저 Spring Boot 3.2.x 또는 3.3.x를 지원하는 Spring Initializr을 사용하세요. 필요한 AI 모델 및 벡터 스토어를 선택하고, Gradle 또는 Maven을 사용하여 시작하십시오. 시작하려면 start.spring.io를 방문하세요. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/getting-started.html>)"
"스프링 AI의 최신 버전을 사용하기 위해 의존성 버전을 관리하는 방법은 무엇인가요?","Spring AI Bill of Materials (BOM)을 사용하여 스프링 AI의 권장 의존성 버전을 선언할 수 있습니다. BOM을 사용하면 직접 의존성 버전을 지정하고 유지할 필요가 없습니다. 대신, 사용하는 BOM의 버전이 활용되는 의존성 버전을 결정합니다. Maven 사용자는 pom.xml 파일에 BOM을 추가하여 사용할 수 있고, Gradle 사용자는 Gradle의 네이티브 지원을 활용하여 BOM을 사용할 수 있습니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/getting-started.html>)"
"스프링 AI의 샘플 프로젝트를 어떻게 찾을 수 있나요?","GitHub에서 Flight Booking Assistant, AI-powered system that has access to terms and conditions (Retrieval Augmented Generation, RAG), access tools (Java methods) to perform actions (Function Calling) and uses an LLM to interact with the user, OpenAI, Azure OpenAI 등의 샘플 프로젝트를 찾을 수 있습니다. 이러한 프로젝트를 GitHub에서 복제하여 시작할 수 있습니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/getting-started.html>)"
"Spring AI API는 어떤 핵심 기능을 제공하나요?","Spring AI API는 AI 모델 API, 벡터 스토어 API, 함수 호출 API를 제공합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/index.html)"
"Spring AI의 AI 모델 API는 어떤 기능을 지원하나요?","Spring AI의 AI 모델 API는 채팅, 텍스트에서 이미지로, 오디오 전사, 텍스트에서 음성, 임베딩 모델에 대한 동기 및 스트림 API 옵션을 제공합니다. 또한 모델 특정 기능에 액세스하기 위해 드롭다운을 지원합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/index.html)"
"Spring AI에서 ETL 데이터 엔지니어링은 어떤 역할을 하나요?","Spring AI의 ETL 프레임워크는 데이터 엔지니어링을 위한 기반을 제공하여 벡터 데이터베이스에 데이터를 로드하고 검색 증강 생성 패턴을 구현하여 AI 모델 응답에 데이터를 통합하는 데 도움이 됩니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/index.html)"
"Spring Ecosystem의 ChatClient API는 어떤 목적으로 사용되나요?","Spring Ecosystem의 ChatClient API는 AI 모델과 통신하기 위한 유창한 API를 제공합니다. 이 API는 동기 및 스트리밍 프로그래밍 모델을 모두 지원합니다."
"Spring Ecosystem의 ChatClient API에서 Prompt는 무엇인가요?","Spring Ecosystem의 ChatClient API에서 Prompt는 AI 모델에 입력으로 전달되는 구성 요소를 구축하는 메서드를 가지고 있습니다. Prompt에는 AI 모델의 출력과 동작을 안내하는 지시 텍스트가 포함되어 있습니다."
"Spring Ecosystem의 ChatClient API에서 Prompt 옵션에는 어떤 것이 있나요?","Spring Ecosystem의 ChatClient API에서 Prompt 옵션에는 사용할 AI 모델의 이름과 생성된 출력의 무작위성 또는 창의성을 제어하는 온도 설정이 포함됩니다."
"스프링 AI 어드바이저 API란 무엇인가요?","스프링 AI 어드바이저 API는 스프링 애플리케이션에서 AI 기반 상호작용을 가로채고 수정하며 향상시키는 데 사용되는 유연한 강력한 방법을 제공합니다. 개발자는 어드바이저 API를 활용하여 더 정교하고 재사용 가능하며 유지 관리 가능한 AI 구성 요소를 만들 수 있습니다."
"어드바이저 API를 사용하는 주요 이점은 무엇인가요?","어드바이저 API의 주요 이점은 반복적인 생성형 AI 패턴을 캡슐화하고, 언어 모델(LLM) 간에 전송되는 데이터를 변환하며, 다양한 모델 및 사용 사례에 대한 이식성을 제공하는 것입니다."
"어드바이저 API를 사용하면 어떤 핵심 구성 요소가 제공되나요?","API는 비 스트리밍 시나리오의 경우 CallAroundAdvisor 및 CallAroundAdvisorChain을 포함하고, 스트리밍 시나리오의 경우 StreamAroundAdvisor 및 StreamAroundAdvisorChain을 포함합니다. 또한 AdvisedRequest는 봉인되지 않은 Prompt 요청을 나타내고, AdvisedResponse는 Chat Completion 응답을 나타냅니다."
"Chat Model API는 어떤 기능을 제공하나요?","Chat Model API는 개발자들이 AI 기반 채팅 완성 기능을 애플리케이션에 통합할 수 있도록 합니다. 이 API는 사전 훈련된 언어 모델인 GPT(Generative Pre-trained Transformer)를 활용하여 자연어 입력을 기반으로 인간과 유사한 응답을 생성합니다."
"Chat Model과 StreamingChatModel 인터페이스에는 어떤 차이점이 있나요?","ChatModel 인터페이스는 AI 모델과의 상호작용을 위한 간단한 인터페이스를 제공하며, 최종 사용자에게 직접 호출되도록 의도되었습니다. 반면에, StreamingChatModel 인터페이스는 반응형 Flux API를 사용하여 응답을 스트리밍합니다."
"Prompt 클래스의 역할은 무엇인가요?","Prompt 클래스는 AI 모델에 대한 입력으로 전달되는 Message 객체의 목록과 선택적 모델 요청 옵션을 캡슐화하는 ModelRequest입니다. Prompt는 대화를 시작하고 AI 모델에게 추가 컨텍스트를 제공하는 데 사용됩니다."
"Amazon Bedrock는 무엇인가요?","Amazon Bedrock는 다양한 AI 제공업체의 기반 모델을 통합 API를 통해 제공하는 관리형 서비스입니다."
"Spring AI는 Amazon Bedrock를 어떻게 지원하나요?","Spring AI는 Amazon Bedrock에서 제공하는 모든 Chat 및 Embedding AI 모델을 지원하며, ChatModel, StreamingChatModel 및 EmbeddingModel과 같은 Spring 인터페이스를 구현합니다."
"Spring AI를 사용하여 Amazon Bedrock에 액세스하려면 어떻게 해야 하나요?","Spring AI를 사용하여 Amazon Bedrock에 액세스하려면 먼저 프로젝트에 Spring Boot 스타터를 추가하고 AWS 자격 증명을 얻은 다음 사용할 모델에 대한 액세스를 구성해야 합니다."
"Anthropic의 Claude는 어떤 AI 어시스턴트인가요?","Anthropic의 Claude는 도움이 되고 정직하며 무해한 AI 시스템을 훈련시키는 Anthropic의 연구를 기반으로 한 AI 어시스턴트입니다."
"Claude 모델의 주요 기능은 무엇인가요?","Claude 모델의 주요 기능은 200k 토큰 컨텍스트 윈도우, 요약, Q&A, 트렌드 예측 및 문서 비교와 같은 지원 작업, AI 안전 기능입니다."
"Spring AI는 Anthropic의 Claude에 어떻게 접근하나요?","Spring AI는 Anthropic의 Claude에 접근하기 위해 전용 Anthropic Claude 클라이언트를 제공합니다."
"Spring AI에서 AWS Bedrock Cohere chat model을 사용하려면 어떻게 해야 하나요?","AWS Bedrock Cohere chat model을 사용하려면 먼저 Spring AI 문서를 참조하여 API 액세스를 설정해야 합니다. 그런 다음 Spring AI 아티팩트를 빌드 시스템에 추가하고 Spring AI BOM을 추가하여 종속성을 관리해야 합니다. 다음으로, 프로젝트의 Maven pom.xml 또는 Gradle build.gradle 파일에 spring-ai-bedrock-ai-spring-boot-starter 종속성을 추가해야 합니다. Cohere chat support를 활성화하고 환경 변수를 설정하여 속성을 구성해야 합니다. 마지막으로, 연결을 구성하기 위해 spring.ai.bedrock.aws 속성을 사용하고, Cohere chat model을 구성하기 위해 spring.ai.bedrock.cohere.chat 속성을 사용해야 합니다."
"Spring AI에서 AWS Bedrock Cohere chat model을 사용하여 요청 특정 런타임 옵션을 어떻게 사용할 수 있나요?","Spring AI에서 AWS Bedrock Cohere chat model을 사용하여 요청 특정 런타임 옵션을 사용하려면 Prompt 호출에 런타임 옵션을 추가할 수 있습니다. 런타임 옵션은 BedrockCohereChatOptions 인스턴스 또는 ChatOptions 인스턴스를 사용하여 설정할 수 있습니다. 예를 들어, 기본 온도를 재정의하려면 Prompt 호출에 BedrockCohereChatOptions.builder()를 사용하여 새로운 옵션을 추가할 수 있습니다."
"Spring AI에서 Cohere chat model을 수동으로 구성하려면 어떻게 해야 하나요?","Spring AI에서 Cohere chat model을 수동으로 구성하려면 먼저 프로젝트의 Maven pom.xml 또는 Gradle build.gradle 파일에 spring-ai-bedrock 종속성을 추가해야 합니다. 그런 다음 CohereChatBedrockApi를 사용하여 BedrockCohereChatModel을 만들고 텍스트 생성에 사용할 수 있습니다. CohereChatBedrockApi를 사용하여 동기식 또는 스트리밍 요청을 할 수 있으며, cohere.command-light-text-v14 및 cohere.command-text-v14 모델을 지원합니다."
"Amazon Titan은 무엇인가요?","Amazon Titan은 Amazon에서 제공하는 재단 모델(FMs)로, 고객들에게 고품질의 이미지, 멀티모달 임베딩, 텍스트 모델 선택지를 제공합니다. 이 모델들은 대규모 데이터셋에서 사전 학습되어 다양한 사용 사례를 지원하며, AWS에서 호스팅되는 모델을 사용하여 완전히 관리되는 API를 통해 액세스할 수 있습니다. 이 모델들은 Amazon Bedrock User Guide에서 설명된 대로 사용할 수 있으며, AWS Bedrock Model Page에서 자세한 정보를 확인할 수 있습니다."
"Spring AI는 Titan 모델과 어떻게 통합되나요?","Spring AI는 Titan 모델과 통합하기 위해 spring-ai-bedrock-ai-spring-boot-starter 종속성을 프로젝트의 Maven pom.xml 또는 Gradle build.gradle 파일에 추가해야 합니다. 또한, AWS Bedrock과의 연결을 구성하기 위해 spring.ai.bedrock.aws 접두사를 사용하고, Titan 채팅 모델 구현을 구성하기 위해 spring.ai.bedrock.titan.chat 접두사를 사용해야 합니다. Titan 모델은 기본적으로 비활성화되어 있으며, spring.ai.bedrock.titan.chat.enabled 속성을 true로 설정하여 활성화할 수 있습니다. 또한, Runtime Options를 사용하여 Prompt 호출에 요청별 옵션을 추가하여 런타임에 기본 옵션을 재정의할 수 있습니다."
"Titan Chat의 모델 ID 값은 어떻게 확인할 수 있나요?","Titan Chat의 모델 ID 값은 TitanChatBedrockApi#TitanChatModel에서 확인할 수 있습니다. AWS Bedrock 문서에서 기본 모델 ID도 확인할 수 있습니다."
"Jurassic은 Spring에서 어떤 역할을 하나요?","Jurassic은 AI21 Labs의 신뢰할 수 있는 FM(Frequently Metrics) 패밀리로, 기업에서 정교한 언어 생성 작업을 지원합니다. 이 작업에는 질문 답변, 텍스트 생성, 검색 및 요약과 같은 작업이 포함됩니다. 이러한 작업은 수천 개의 라이브 애플리케이션에서 실행됩니다."
"Spring AI 아티팩트는 어디에서 게시되나요?","Spring AI 아티팩트는 Spring Milestone 및 Snapshot 저장소에 게시됩니다."
"Spring AI BOM은 무엇인가요?","Spring AI BOM(bill of materials)은 일관된 버전의 Spring AI가 프로젝트 전체에서 사용되도록 하는 데 도움이 됩니다."
"Spring AI에서 Anthropic의 Claude 모델을 어떻게 사용할 수 있나요?","Spring AI는 Anthropic의 Claude 모델을 지원하기 위해 Anthropic Messaging API를 위한 동기 및 스트리밍 텍스트 생성을 위한 Anthropic Chat 클라이언트를 제공합니다. Anthropic API 키를 생성하고, 빌드 시스템에 Spring AI 저장소와 BOM을 추가하고, 프로젝트에 spring-ai-anthropic-spring-boot-starter 종속성을 추가하고, Anthropic Chat 클라이언트를 위한 속성을 구성해야 합니다."
"Spring AI의 Anthropic Chat 클라이언트에서 재시도 정책을 어떻게 구성할 수 있나요?","Spring AI의 Anthropic Chat 클라이언트에서 재시도 정책은 spring.ai.retry 접두사를 사용하여 구성할 수 있습니다. 최대 재시도 횟수, 백오프 간격 및 재시도할 HTTP 상태 코드를 지정할 수 있습니다. 현재 재시도 정책은 스트리밍 API에 적용되지 않습니다."
"Spring AI의 Anthropic Chat 클라이언트에서 사용자 정의 함수를 등록하고 호출하는 방법은 무엇인가요?","Spring AI의 Anthropic Chat 클라이언트에서 사용자 정의 Java 함수를 AnthropicChatModel에 등록하고 Anthropic Claude 모델이 등록된 함수 중 하나를 호출하기 위한 인수를 포함하는 JSON 개체를 지능적으로 선택하도록 할 수 있습니다. 이는 LLM 기능을 외부 도구 및 API와 연결하는 강력한 기술입니다. AnthropicChatModel에서 functionCallbacks 속성을 사용하여 도구 함수 콜백을 등록할 수 있습니다."
"Azure OpenAI Chat은 Azure의 OpenAI 제공과 어떻게 다른가요?","Azure의 OpenAI 제공인 Azure OpenAI Chat은 전통적인 OpenAI 기능을 넘어서 향상된 기능을 제공하는 AI 기반 텍스트 생성을 제공합니다. Azure는 추가적인 AI 안전 및 책임 있는 AI 기능을 제공하며, 최신 업데이트는 https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/announcing-new-ai-safety-amp-responsible-ai-features-in-azure/ba-p/3983686에서 확인할 수 있습니다."
"Azure는 Java 개발자에게 어떤 기회를 제공하나요?","Azure는 Java 개발자가 AI의 모든 잠재력을 활용할 수 있도록 다양한 Azure 서비스와 통합할 수 있는 기회를 제공합니다. 이에는 Azure의 벡터 스토어와 같은 AI 관련 리소스가 포함됩니다."
"Azure OpenAI 클라이언트에 연결하기 위한 사전 요구 사항은 무엇인가요?","Azure OpenAI 클라이언트에 연결하기 위한 사전 요구 사항은 Azure API 키 또는 OpenAI API 키를 사용하거나 Microsoft Entra ID를 사용하는 것입니다."
"VertexAI API는 무엇인가요?","VertexAI API는 최소한의 머신 러닝 전문 지식과 노력으로 고품질의 맞춤형 머신 러닝 모델을 제공하는 API입니다. (출처: https://cloud.google.com/vertex-ai/docs/reference)"
"Spring AI는 VertexAI API와 어떤 클라이언트를 통해 통합되나요?","Spring AI는 VertexAI PaLM2 Chat, VertexAI Gemini Chat, Function Calling, VertexAI PaLM2와 같은 클라이언트를 통해 VertexAI API와 통합됩니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/chat/google-vertexai.html)"
"VertexAI API의 공식 문서는 어디에서 찾을 수 있나요?","VertexAI API의 공식 문서는 Google Cloud의 VertexAI 문서 페이지에서 확인할 수 있습니다. (출처: https://cloud.google.com/vertex-ai/docs/reference)"
"생성형 AI 애플리케이션이란 무엇인가요?","생성형 AI 애플리케이션은 일련의 프롬프트를 통해 컴퓨터가 자연어를 이해하고 생성할 수 있는 강력하고 다용도한 기계 학습 모델인 Large Language Models (LLMs)을 사용하는 애플리케이션입니다. PaLM API를 사용하여 콘텐츠 생성, 대화 에이전트, 요약 및 분류 시스템 등과 같은 사용 사례에 대한 생성형 AI 애플리케이션을 구축할 수 있습니다. 출처: <https://developers.generativeai.google/api/rest/generativelanguage>"
"PaLM2 REST API에 액세스하려면 어떤 API 키가 필요한가요?","PaLM2 REST API에 액세스하려면 makersuite(https://makersuite.google.com/app/apikey)에서 액세스 API 키를 획득해야 합니다. 현재 PaLM API는 미국 외부에서는 사용할 수 없지만, 테스트를 위해 VPN을 사용할 수 있습니다. Spring AI 프로젝트는 API 키의 값으로 설정해야 하는 spring.ai.vertex.ai.api-key라는 구성 속성을 정의합니다. 환경 변수를 내보내는 것은 해당 구성 속성을 설정하는 한 가지 방법입니다. 출처: <https://developers.generativeai.google/api/rest/generativelanguage/models>"
"Spring AI에서 VertexAI Chat Client에 대한 Spring Boot 자동 구성을 사용하려면 어떻게 해야 하나요?","Spring AI에서 VertexAI Chat Client에 대한 Spring Boot 자동 구성을 사용하려면 다음 종속성을 프로젝트의 Maven pom.xml 파일에 추가하거나 Gradle build.gradle 빌드 파일에 추가하십시오. <dependency> <groupId>org.springframework.ai</groupId> <artifactId>spring-ai-vertex-ai-palm2-spring-boot-starter</artifactId> </dependency> 또는 dependencies { implementation 'org.springframework.ai:spring-ai-vertex-ai-palm2-spring-boot-starter' } Spring AI BOM을 빌드 파일에 추가하려면 Dependency Management(../../getting-started.html#dependency-management) 섹션을 참조하십시오. 출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/chat/vertexai-palm2-chat.html>"
"Vertex AI Gemini API는 무엇인가요?","Vertex AI Gemini API는 개발자가 Gemini 모델을 사용하여 생성형 AI 애플리케이션을 구축할 수 있도록 하는 API입니다. 이 API는 이미지, 비디오 및 텍스트를 포함한 여러 모달리티의 정보를 처리할 수 있는 멀티모달 모델을 지원하며, 입력 및 출력은 텍스트 또는 코드입니다."
"Gemini 모델은 무엇인가요?","Gemini는 Google DeepMind에서 개발한 멀티모달 사용 사례를 위해 설계된 생성형 AI 모델 패밀리입니다. Vertex AI Gemini API를 통해 Gemini 1.0 Pro Vision 및 Gemini 1.0 Pro 모델에 액세스할 수 있습니다."
"Spring AI는 Vertex AI Gemini Chat Client에 대해 어떤 기능을 제공하나요?","Spring AI는 Vertex AI Gemini Chat Client에 대해 Spring Boot 자동 구성을 제공하여 Vertex AI Gemini에 연결하고 멀티모달 프롬프트를 사용하고 텍스트 또는 코드를 생성할 수 있도록 합니다. 또한, 채팅 모델 구현을 구성하기 위한 속성 접두사와 런타임에서 프롬프트 호출에 대한 요청별 옵션을 허용합니다."
"스프링 AI에서 커스텀 함수를 등록하고 호출하는 방법은 무엇인가요?","스프링 AI에서는 VertexAiGeminiChatModel Auto-Configuration을 사용하여 스프링 컨텍스트에서 커스텀 함수를 빈으로 등록하는 여러 가지 방법이 있습니다. 가장 POJO 친화적인 옵션부터 시작하여 @Bean을 정의하고 내부적으로 Spring AI ChatModel이 AI 모델을 통해 호출되는 로직을 추가하는 FunctionCallbackWrapper의 인스턴스를 생성합니다. @Bean의 이름은 ChatOption으로 전달되며, @Description 어노테이션은 선택 사항이며 함수 설명을 제공하여 모델이 함수를 호출할 때를 이해하는 데 도움이 됩니다. 또 다른 옵션은 MockWeatherService와 같은 FunctionCallbackWrapper를 만드는 것입니다. 이는 3rd party MockWeatherService 함수를 래핑하고 VertexAiGeminiChatModel에 CurrentWeather 함수로 등록하며 설명과 스키마 유형을 제공합니다. 함수를 호출하려면 Prompt 요청에서 활성화해야 합니다. 또한 Prompt 요청에 콜백 함수를 동적으로 등록할 수 있습니다. VertexAiGeminiChatModel chatModel = ... UserMessage userMessage = new UserMessage('What's the weather like in San Francisco, Tokyo, and Paris? Use Multi-turn function calling.'); var promptOptions = VertexAiGeminiChatOptions.builder() .withFunctionCallbacks(List.of(FunctionCallbackWrapper.builder(new MockWeatherService()) .withName('CurrentWeather') .withSchemaType(SchemaType.OPEN_API) // IMPORTANT!! .withDescription('Get the weather in location') .build())) .build(); ChatResponse response = chatModel.call(new Prompt(List.of(userMessage), promptOptions));"
"스프링 AI에서 커스텀 함수를 등록하기 위해 @Description 어노테이션을 사용하는 방법은 무엇인가요?","@Description 어노테이션은 선택 사항이며 함수 설명을 제공하여 모델이 함수를 호출할 때를 이해하는 데 도움이 됩니다. 이는 함수를 호출할 때를 결정하는 데 도움이 되는 중요한 속성입니다. 함수의 설명을 제공하는 또 다른 옵션은 MockWeatherService.Request에 @JsonClassDescription 어노테이션을 사용하여 함수 설명을 제공하는 것입니다."
"스프링 AI에서 커스텀 함수를 등록하기 위해 FunctionCallbackWrapper를 사용하는 방법은 무엇인가요?","FunctionCallbackWrapper를 사용하여 함수를 등록하는 방법은 다음과 같습니다. @Configuration static class Config { @Bean public FunctionCallback weatherFunctionInfo() { return FunctionCallbackWrapper.builder(new MockWeatherService()) .withName('CurrentWeather') // (1) 함수 이름 .withDescription('Get the current weather in a given location') // (2) 함수 설명 .withSchemaType(SchemaType.OPEN_API) // (3) 스키마 유형. Gemini 함수 호출에 필수입니다. .build(); } ... } 이는 3rd party MockWeatherService 함수를 래핑하여 VertexAiGeminiChatModel에 CurrentWeather 함수로 등록하고 설명과 스키마 유형을 제공합니다. 기본 응답 변환기는 Response 개체의 JSON 직렬화를 수행합니다. FunctionCallbackWrapper는 내부적으로 MockWeatherService.Request 클래스를 기반으로 함수 호출 서명을 해결하고 함수 호출에 대한 Open API 스키마를 내부적으로 생성합니다."
"Groq Chat은 무엇인가요?","Groq Chat은 Groq에서 제공하는 AI Inference Engine으로, 다양한 AI 모델을 지원하며, 도구/함수 호출을 지원하고 OpenAI API와 호환되는 엔드포인트를 노출합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/chat/groq-chat.html)"
"Groq Chat을 사용하려면 어떤 전제 조건이 필요한가요?","Groq Chat을 사용하려면 API 키를 생성하고, Groq URL을 설정하고, Groq 모델을 선택해야 합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/chat/groq-chat.html)"
"Groq Chat을 사용하기 위해 필요한 속성은 무엇인가요?","Groq Chat을 사용하기 위해 필요한 속성은 API 키, Groq URL, 그리고 Groq 모델입니다. 이 속성들은 환경 변수로 설정하거나 Spring AI 프로젝트에서 해당 구성 속성을 설정하여 사용할 수 있습니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/chat/groq-chat.html)"
"Hugging Face Inference Endpoints란 무엇인가요?","Hugging Face Inference Endpoints는 클라우드에서 머신러닝 모델을 배포하고 API를 통해 액세스할 수 있는 기능을 제공합니다. 이 엔드포인트를 사용하면 Hugging Face에서 모델을 프로비저닝할 때 얻은 추론 엔드포인트 URL을 spring.ai.huggingface.chat.url 구성 속성에 설정해야 합니다."
"Spring AI 프로젝트에서 Hugging Face Chat의 API 키를 구성하려면 어떻게 해야 하나요?","Spring AI 프로젝트에서 Hugging Face Chat의 API 키를 구성하려면 spring.ai.huggingface.chat.api-key 구성 속성을 설정하고 얻은 API 토큰의 값으로 설정해야 합니다. 환경 변수를 내보내는 것은 이 구성 속성을 설정하는 한 가지 방법입니다."
"Spring AI는 Hugging Face Chat Client에 대한 자동 구성을 제공하나요?","네, Spring AI는 Hugging Face Chat Client에 대한 Spring Boot 자동 구성을 제공합니다. 이를 사용하려면 프로젝트의 Maven pom.xml 또는 Gradle build.gradle 파일에 spring-ai-huggingface-spring-boot-starter 종속성을 추가해야 합니다. 또한 Spring AI BOM을 빌드 파일에 추가해야 합니다."
"스프링 AI에서 Mistral AI 언어 모델을 사용하는 방법은 무엇인가요?","스프링 AI는 Mistral AI의 다양한 AI 언어 모델을 지원합니다. Mistral AI 언어 모델과 상호 작용하고 Mistral 모델을 기반으로 다국어 대화형 어시스턴트를 만들 수 있습니다. 프로젝트에서 spring.ai.mistralai.api-key 구성을 설정하고 Spring AI BOM을 추가하고 Mistral AI Chat Client에 대한 Spring Boot 자동 구성을 활성화하여 Mistral AI 언어 모델을 사용할 수 있습니다."
"Mistral AI에서 OpenAI API 호환 엔드포인트를 사용할 때 고려해야 할 특정 설정이 있나요?","Mistral AI는 OpenAI API 호환 엔드포인트를 제공합니다. Mistral AI에서 OpenAI API 호환 엔드포인트를 사용할 때 spring.ai.openai.chat.base-url, spring.ai.openai.chat.options.model 및 spring.ai.openai.chat.api-key 속성을 설정해야 합니다. 이러한 속성을 설정하여 OpenAI 엔드포인트를 가리키고 Mistral 모델을 선택하고 Mistral AI API 키를 설정할 수 있습니다."
"스프링 AI에서 Mistral AI 언어 모델을 사용하는 경우 재시도 및 백오프 속성은 무엇인가요?","스프링 AI는 Mistral AI 채팅 모델의 재시도 메커니즘을 구성할 수 있는 속성 접두사 spring.ai.retry를 제공합니다. 재시도 속성에는 최대 재시도 횟수, 지수 백오프 정책의 초기 수면 기간, 백오프 간격 배수 및 최대 백오프 기간이 포함됩니다. 또한 4xx 클라이언트 오류 코드에 대해 재시도를 시도하지 않으려면 spring.ai.retry.on-client-errors 속성을 false로 설정할 수 있습니다."
"스프링 생태계의 MiniMax Chat Spring AI는 어떤 기능을 제공하나요?","MiniMax의 다양한 AI 언어 모델을 지원하며, MiniMax 언어 모델과 상호 작용하고 MiniMax 모델을 기반으로 다국어 대화 지원 도구를 만들 수 있습니다."
"MiniMax 언어 모델에 액세스하려면 어떻게 해야 하나요?","MiniMax와 API를 생성하여 MiniMax 언어 모델에 액세스할 수 있습니다. MiniMax 등록 페이지(https://www.minimaxi.com/login)에서 계정을 만들고 API 키 페이지(https://www.minimaxi.com/user-center/basic-information/interface-key)에서 토큰을 생성하세요."
"MiniMax Chat Spring AI를 사용하려면 어떤 전제 조건이 필요한가요?","MiniMax와 API를 생성하여 MiniMax 언어 모델에 액세스해야 합니다. 또한, Spring AI 프로젝트는 spring.ai.minimax.api-key라는 구성 속성을 정의하므로 해당 속성을 API 키 페이지(https://www.minimaxi.com/user-center/basic-information/interface-key)에서 얻은 API 키의 값으로 설정해야 합니다."
"스프링 AI에서 Moonshot AI 언어 모델을 사용하려면 어떤 사전 요구 사항이 필요한가요?","Moonshot AI 언어 모델에 액세스하려면 Moonshot에서 API를 생성해야 합니다. Moonshot AI 등록 페이지(https://platform.moonshot.cn/console)에서 계정을 만들고 API 키 페이지(https://platform.moonshot.cn/console/api-keys/)에서 토큰을 생성하세요."
"Spring AI에서 Moonshot Chat Model을 구성하는 방법은 무엇인가요?","Moonshot Chat Model을 사용하려면 프로젝트의 Maven pom.xml 파일에 다음 종속성을 추가하세요: <dependency> <groupId>org.springframework.ai</groupId> <artifactId>spring-ai-moonshot-spring-boot-starter</artifactId> </dependency> 또는 Gradle build.gradle 빌드 파일에 다음을 추가하세요: dependencies { implementation 'org.springframework.ai:spring-ai-moonshot-spring-boot-starter' } 빌드 파일에 Spring AI BOM을 추가하려면 Dependency Management(../../getting-started.html#dependency-management) 섹션을 참조하세요."
"Spring AI에서 Moonshot Chat Model의 재시도 메커니즘을 구성하는 방법은 무엇인가요?","Moonshot AI Chat 모델의 재시도 메커니즘을 구성하려면 spring.ai.retry 접두사를 사용하여 속성 접두사를 사용하세요. spring.ai.retry.max-attempts는 재시도 시도의 최대 수를 지정합니다. 기본값은 10입니다. spring.ai.retry.backoff.initial-interval은 지수 백오프 정책의 초기 수면 기간을 정의합니다. 기본값은 2초입니다. spring.ai.retry.backoff.multiplier는 백오프 간격 승수를 지정합니다. 기본값은 5입니다. spring.ai.retry.backoff.max-interval은 최대 백오프 기간을 정의합니다. 기본값은 3분입니다. spring.ai.retry.on-client-errors는 클라이언트 오류 코드에 대해 재시도를 시도하지 않고 NonTransientAiException을 던져야 하는지 여부를 지정합니다. 기본값은 false입니다. spring.ai.retry.exclude-on-http-codes는 재시도를 트리거하지 않아야 하는 HTTP 상태 코드 목록입니다. 기본값은 비어 있습니다. spring.ai.retry.on-http-codes는 재시도를 트리거해야 하는 HTTP 상태 코드 목록입니다. 기본값은 비어 있습니다."
"Spring AI에서 NVIDIA LLM API와의 통합은 어떻게 이루어지나요?","Spring AI는 기존의 OpenAI 클라이언트를 재사용하여 NVIDIA LLM API와 통합됩니다. 이를 위해서는 base-url을 https://integrate.api.nvidia.com로 설정하고, 제공된 LLM 모델 중 하나를 선택한 후 해당 모델에 대한 API 키를 얻어야 합니다."
"Spring AI에서 NVIDIA LLM API를 사용하기 위한 사전 요구 사항은 무엇인가요?","NVIDIA LLM API를 사용하기 위해서는 NVIDIA 계정을 생성하고, 충분한 크레딧을 보유하고 있어야 합니다. 또한, 사용할 LLM 모델을 선택하고, 해당 모델의 API 키를 얻어야 합니다."
"Spring AI에서 NVIDIA LLM API를 사용하기 위한 OpenAI Chat Client의 자동 구성은 어떻게 이루어지나요?","Spring AI는 OpenAI Chat Client에 대한 Spring Boot 자동 구성을 제공합니다. 이를 사용하려면 프로젝트의 Maven pom.xml 파일 또는 Gradle build.gradle 빌드 파일에 spring-ai-openai-spring-boot-starter 종속성을 추가해야 합니다."
"올라마를 사용하여 로컬에서 다양한 대규모 언어 모델을 실행하는 방법은 무엇인가요?","올라마를 사용하여 로컬에서 다양한 대규모 언어 모델을 실행하려면, 먼저 공식 올라마 프로젝트 README를 참조하여 로컬에서 모델을 실행해야 합니다. 그러나 Spring AI는 OllamaChatModel API를 제공하여 올라마 텍스트 생성 기능을 지원합니다. Spring AI OpenAI 프로젝트를 사용하여 올라마 서버와 대화할 수도 있습니다."
"Spring AI Ollama Spring Boot 스타터를 사용하려면 어떻게 해야 하나요?","Spring AI Ollama Spring Boot 스타터를 사용하려면 프로젝트의 Maven pom.xml 파일 또는 Gradle build.gradle 빌드 파일에 다음 종속성을 추가하십시오. 그런 다음 Spring AI BOM을 빌드 파일에 추가하여 종속성 관리를 용이하게 하십시오. Spring AI는 또한 Ollama 채팅 통합을 위한 Spring Boot 자동 구성을 제공합니다."
"Ollama의 기본 연결 속성은 무엇이며, 어떻게 사용자 정의할 수 있나요?","Ollama의 기본 연결 속성은 spring.ai.ollama.base 속성으로, 기본값은 http://localhost:11434입니다. 이 속성을 사용자 정의하여 Ollama API 서버가 실행되는 기본 URL을 변경할 수 있습니다. 또한, spring.ai.ollama.chat.options 접두사로 시작하는 속성은 Ollama 채팅 모델 및 모델 옵션을 구성합니다."
"Spring AI에서 OpenAI의 채팅 모델에 대해 재시도 메커니즘을 구성하는 데 사용되는 속성 접두사는 무엇인가요?","spring.ai.retry"
"Spring AI에서 OpenAI의 채팅 모델에 대한 기본 URL은 무엇인가요?","api.openai.com"
"Spring AI에서 OpenAI의 채팅 구현을 구성하는 데 사용되는 속성 접두사는 무엇인가요?","spring.ai.openai.chat"
"스프링 AI에서 커스텀 함수를 등록하는 방법은 무엇인가요?","스프링 AI에서는 OpenAiChatModel Auto-Configuration을 통해 커스텀 함수를 스프링 컨텍스트에 빈으로 등록하는 다양한 방법을 제공합니다. 가장 간단한 방법은 @Bean을 사용하여 다른 스프링 관리 객체와 마찬가지로 정의하는 것입니다. 내부적으로 스프링 AI ChatModel은 AI 모델을 통해 호출될 때를 위한 로직을 추가하는 FunctionCallbackWrapper의 인스턴스를 생성합니다. @Bean의 이름은 ChatOption으로 전달됩니다. @Description 어노테이션은 선택 사항이며, 모델이 함수를 호출할 때를 이해하는 데 도움이 되는 함수 설명을 제공합니다. 이는 AI 모델이 어떤 클라이언트 측 함수를 호출해야 하는지 결정하는 데 도움이 되는 중요한 속성입니다. 함수의 설명을 제공하는 또 다른 옵션은 MockWeatherService.Request에 @JsonClassDescription 어노테이션을 사용하는 것입니다."
"스프링 AI에서 커스텀 함수를 호출하는 방법은 무엇인가요?","모델에게 CurrentWeather 함수를 알고 호출하도록 하려면 프롬프트 요청에서 이를 활성화해야 합니다. OpenAiChatModel chatModel = ... UserMessage userMessage = new UserMessage('샌프란시스코, 도쿄, 파리의 날씨는 어때요?'); ChatResponse response = chatModel.call(new Prompt(userMessage, OpenAiChatOptions.builder().withFunction('CurrentWeather').build()));"
"스프링 AI에서 커스텀 함수를 등록하는 데 FunctionCallbackWrapper를 사용하는 방법은 무엇인가요?","@Configuration static class Config { @Bean public FunctionCallback weatherFunctionInfo() { return FunctionCallbackWrapper.builder(new MockWeatherService()).withName('CurrentWeather') // (1) 함수 이름 .withDescription('Get the weather in location') // (2) 함수 설명 .build(); } }"
"QianFan Chat을 Spring 애플리케이션에서 사용하려면 어떤 전제 조건이 필요한가요?","QianFan과 함께 API를 생성하여 QianFan 언어 모델에 액세스해야 합니다. QianFan 등록 페이지(https://login.bce.baidu.com/new-reg)에서 계정을 만들고 API 키 페이지(https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application)에서 토큰을 생성해야 합니다."
"Spring AI 프로젝트에서 QianFan 언어 모델을 구성하려면 어떤 구성 속성을 설정해야 하나요?","Spring AI 프로젝트는 spring.ai.qianfan.api-key 및 spring.ai.qianfan.secret-key라는 구성 속성을 정의합니다. 이 속성은 API 키 페이지(https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application)에서 얻은 API 키 및 비밀 키의 값으로 설정해야 합니다."
"Spring AI 프로젝트에서 QianFan Chat Client에 대한 Spring Boot 자동 구성을 활성화하려면 어떻게 해야 하나요?","프로젝트의 Maven pom.xml 파일에 다음 종속성을 추가하십시오: <dependency> <groupId>org.springframework.ai</groupId> <artifactId>spring-ai-qianfan-spring-boot-starter</artifactId> </dependency> 또는 Gradle build.gradle 빌드 파일에 다음 종속성을 추가하십시오: dependencies { implementation 'org.springframework.ai:spring-ai-qianfan-spring-bot-starter' }"
"ZhiPu AI Chat과 상호작용하고 ZhiPuAI 모델을 기반으로 다국어 대화형 어시스턴트를 만들기 위해 필요한 전제 조건은 무엇인가요?","ZhiPuAI와 상호작용하려면 ZhiPuAI에서 API를 생성하여 ZhiPuAI 언어 모델에 액세스해야 합니다. ZhiPu AI 등록 페이지(https://open.bigmodel.cn/login)에서 계정을 만들고 API 키 페이지(https://open.bigmodel.cn/usercenter/apikeys)에서 토큰을 생성하세요."
"Spring AI 프로젝트에서 설정해야 하는 구성 속성은 무엇이며, 어떤 값으로 설정해야 하나요?","Spring AI 프로젝트에서는 spring.ai.zhipuai.api-key라는 구성 속성을 설정해야 하며, 이 값은 API 키 페이지(https://open.bigmodel.cn/usercenter/apikeys)에서 얻은 API 키의 값과 동일해야 합니다. 환경 변수를 내보내는 것은 해당 구성 속성을 설정하는 한 가지 방법입니다. 예를 들어, export SPRING_AI_ZHIPU_AI_API_KEY=<INSERT KEY HERE>와 같이 설정하세요."
"Spring AI BOM을 빌드 시스템에 추가하여 일관된 버전의 Spring AI를 사용하는 방법은 무엇인가요?","Spring AI BOM(Bill of Materials)은 빌드 시스템에서 Spring AI에 대한 일관된 버전을 유지하는 데 도움이 됩니다. Spring AI BOM을 빌드 시스템에 추가하려면 Repositories(../../getting-started.html#repositories) 섹션에서 Spring Milestone 및 Snapshot 저장소를 추가하는 지침을 따르세요. 그런 다음 Dependency Management(../../getting-started.html#dependency-management) 섹션에서 빌드 시스템에 Spring AI BOM을 추가하세요."
"Spring AI에서 watsonx.ai Chat을 어떻게 사용하나요?","WatsonxAiChatModel을 사용하여 watsonx.ai SaaS 인스턴스와 IBM Cloud 계정이 필요합니다. 프로젝트의 Maven pom.xml 파일 또는 Gradle build.gradle 빌드 파일에 spring-ai-watsonx-ai-spring-boot-starter 종속성을 추가하여 자동 구성을 활성화할 수 있습니다. spring.ai.watsonx.ai.base, spring.ai.watsonx.ai.stream-endpoint, spring.ai.watsonx.ai.text-endpoint, spring.ai.watsonx.ai.project-id, spring.ai.watsonx.ai.iam-token 속성을 사용하여 watsonx.ai에 연결할 수 있습니다. spring.ai.watsonx.ai.chat.enabled, spring.ai.watsonx.ai.chat.options.temperature, spring.ai.watsonx.ai.chat.options.top-p, spring.ai.watsonx.ai.chat.options.top-k, spring.ai.watsonx.ai.chat.options.decoding-method, spring.ai.watsonx.ai.chat.options.max-new-tokens, spring.ai.watsonx.ai.chat.options.min-new-tokens, spring.ai.watsonx.ai.chat.options.stop-sequences, spring.ai.watsonx.ai.chat.options.repetition-penalty, spring.ai.watsonx.ai.chat.options.random-seed, spring.ai.watsonx.ai.chat.options.model 속성을 사용하여 챗 모델 구현을 구성할 수 있습니다. Prompt 호출에서 새로운 요청별 옵션을 추가하여 런타임에 기본 옵션을 재정의할 수 있습니다."
"WatsonxAiChatOptions에서 어떤 모델 구성을 설정할 수 있나요?","WatsonxAiChatOptions 클래스를 사용하여 사용할 모델, 온도, 빈도수 패널티 등과 같은 모델 구성을 설정할 수 있습니다. WatsonxAiChatModel의 생성자나 spring.ai.watsonxai.chat.options.* 속성을 사용하여 기본 옵션을 구성할 수 있습니다. Prompt 호출에서 새로운 요청별 옵션을 추가하여 런타임에 기본 옵션을 재정의할 수 있습니다."
"watsonx.ai Chat에서 런타임 옵션을 어떻게 재정의할 수 있나요?","Prompt 호출에서 새로운 요청별 옵션을 추가하여 런타임에서 기본 옵션을 재정의할 수 있습니다. WatsonxAiChatOptions.java 클래스 또는 ChatOptionsBuilder#builder() 메서드를 사용하여 만든 ChatOptions 인스턴스를 사용하여 런타임에서 옵션을 재정의할 수 있습니다."
"Spring AI의 EmbeddingModel 인터페이스의 주요 기능은 무엇인가요?","Spring AI의 EmbeddingModel 인터페이스는 텍스트를 수치 벡터로 변환하는 기능을 제공합니다. 이 변환된 수치 벡터는 의미 분석, 텍스트 분류 등 다양한 작업에 사용됩니다. 이 인터페이스는 다양한 임베딩 모델에서 쉽게 적용할 수 있도록 설계되었습니다. 또한, EmbeddingModel 인터페이스는 텍스트를 수치 벡터로 변환하는 과정을 단순화하여 개발자들이 보다 쉽게 임베딩을 활용할 수 있도록 도와줍니다."
"Spring AI의 EmbeddingModel 인터페이스의 주요 목표는 무엇인가요?","Spring AI의 EmbeddingModel 인터페이스의 주요 목표는 이식성과 간편성입니다. 이 인터페이스는 다양한 임베딩 모델에서 쉽게 전환할 수 있도록 설계되어 있습니다. 이를 통해 개발자들은 코드 변경을 최소화하면서 다양한 임베딩 기술이나 모델을 사용할 수 있습니다. 또한, EmbeddingModel 인터페이스는 원시 텍스트 데이터와 임베딩 알고리즘을 다루는 복잡성을 단순화하여 개발자들이 보다 쉽게 임베딩을 활용할 수 있도록 도와줍니다."
"Spring AI의 EmbeddingModel 인터페이스는 어떻게 EmbeddingModel 구현체를 활용하나요?","Spring AI의 EmbeddingModel 인터페이스는 OpenAI, Titan, Azure OpenAI, Ollie 등 다양한 임베딩 모델에 대한 EmbeddingModel 구현체를 제공합니다. 이러한 구현체는 Spring AI Model API 위에 구축되어 있으며, EmbeddingModel 인터페이스의 추상화를 활용하여 각 임베딩 모델의 구체적인 구현을 처리합니다. 이를 통해 개발자들은 EmbeddingModel 인터페이스를 사용하여 다양한 임베딩 모델을 쉽게 사용할 수 있습니다."
"Spring AI가 Amazon Bedrock를 지원하는 방법은 무엇인가요?","Spring AI는 Amazon Bedrock에서 제공하는 Chat 및 Embedding AI 모델을 지원하며, Spring 인터페이스인 ChatModel, StreamingChatModel, EmbeddingModel을 구현합니다. 또한, Spring AI는 모든 클라이언트에 대한 Spring Auto-Configurations 및 Boot Starters를 제공하여 Bedrock 모델을 쉽게 부트스트랩하고 구성할 수 있습니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/bedrock.html)"
"Spring AI를 사용하여 Amazon Bedrock에 연결하려면 어떤 단계를 거쳐야 하나요?","Spring AI를 사용하여 Amazon Bedrock에 연결하려면, 먼저 Spring Boot starter for Bedrock를 프로젝트에 추가해야 합니다. 그 다음, AWS 자격 증명을 획득해야 합니다. AWS CLI 및 SDK 설정 비디오 가이드를 참조할 수 있습니다. 그런 다음, 사용할 모델에 대한 액세스를 구성하기 위해 Amazon Bedrock 콘솔로 이동해야 합니다. 그 다음, Spring Boot Starter 종속성을 프로젝트의 Maven pom.xml 또는 Gradle build.gradle 빌드 파일에 추가해야 합니다. 마지막으로, BedrockAwsConnectionProperties를 사용하여 AWS 자격 증명 및 지역을 구성해야 합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/bedrock.html)"
"Spring AI에서 지원하는 Amazon Bedrock의 모델은 무엇인가요?","Spring AI는 Amazon Bedrock에서 지원하는 모든 Chat 및 Embedding AI 모델을 지원합니다. 이러한 모델에는 Llama, Jurassic2, Cohere, Anthropic 2, Anthropic 3, Titan 등이 포함됩니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/bedrock.html)"
"Spring에서 Cohere Embeddings를 사용하려면 어떻게 해야 하나요?","Spring AI artifacts를 build system에 추가하고 Spring AI BOM을 사용하여 일관된 버전을 유지하세요. 그런 다음 spring-ai-bedrock-ai-spring-boot-starter 종속성을 추가하고 환경 변수를 사용하여 spring.ai.bedrock.cohere.embedding.enabled 속성을 true로 설정하세요. AWS Bedrock에 대한 연결을 구성하기 위해 spring.ai.bedrock.aws 접두사를 사용하고 Cohere Embedding에 대한 모델 구현을 구성하기 위해 spring.ai.bedrock.cohere.embedding 접두사를 사용하세요."
"Spring에서 Cohere Embeddings를 사용하려면 어떤 속성을 설정해야 하나요?","spring.ai.bedrock.aws 접두사를 사용하여 AWS Bedrock에 대한 연결을 구성하고 spring.ai.bedrock.cohere.embedding 접두사를 사용하여 Cohere Embedding에 대한 모델 구현을 구성하세요. spring.ai.bedrock.aws.region, spring.ai.bedrock.aws.access-key, spring.ai.bedrock.aws.secret-key, spring.ai.bedrock.cohere.embedding.model, spring.ai.bedrock.cohere.embedding.options.input-type, spring.ai.bedrock.cohere.embedding.options.truncate 등의 속성을 설정할 수 있습니다."
"Spring에서 BedrockCohereEmbeddingModel을 수동으로 구성하려면 어떻게 해야 하나요?","프로젝트의 Maven pom.xml 파일에 spring-ai-bedrock 종속성을 추가하고 build.gradle 파일에 해당합니다. 그런 다음 spring-ai-bedrock 라이브러리의 BedrockCohereEmbeddingModel 클래스를 사용하여 Low-level CohereEmbeddingBedrockApi 클라이언트를 사용하여 텍스트 임베딩에 사용하세요."
"Bedrock Titan Embedding은 어떤 종류의 임베딩을 지원하나요?","텍스트 및 이미지 임베딩을 지원합니다."
"Bedrock Titan Embedding은 배치 임베딩을 지원하나요?","아니요, 지원하지 않습니다."
"Bedrock Titan Embedding 모델의 사용을 위해서는 어떤 환경 변수를 내보내야 하나요?","spring.ai.bedrock.titan.embedding.enabled"
"Azure OpenAI Embeddings는 어떤 작업을 위해 안전하고 텍스트 생성 및 임베딩 계산 모델을 제공합니까?","유사도 임베딩은 두 개 이상의 텍스트 간의 의미적 유사성을 포착하는 데 유용합니다. 텍스트 검색 임베딩은 긴 문서가 짧은 쿼리와 관련된지 여부를 측정하는 데 도움이 됩니다. 코드 검색 임베딩은 코드 스니펫을 임베딩하고 자연어 검색 쿼리를 임베딩하는 데 유용합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/embeddings/azure-openai-embeddings.html)"
"Azure OpenAI Embeddings를 연결하기 위해 Azure AI OpenAI 클라이언트에서 제공하는 세 가지 옵션은 무엇입니까?","Azure API 키를 사용하거나 OpenAI API 키를 사용하거나 Microsoft Entra ID를 사용하는 것입니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/embeddings/azure-openai-embeddings.html)"
"Azure OpenAI Embedding Model을 활성화하기 위해 프로젝트의 Maven pom.xml 파일에 추가해야 하는 종속성은 무엇입니까?","<dependency> <groupId>org.springframework.ai</groupId> <artifactId>spring-ai-azure-openai-spring-boot-starter</artifactId> </dependency>"
"Mistral AI 임베딩을 사용하려면 어떤 사전 요구 사항이 있나요?","MistralAI와 함께 API를 생성하여 MistralAI 임베딩 모델에 액세스해야 합니다. MistralAI 등록 페이지(https://auth.mistral.ai/ui/registration)에서 계정을 만들고 API 키 페이지(https://console.mistral.ai/api-keys/)에서 토큰을 생성하세요. 그런 다음, spring.ai.mistralai.api-key라는 구성 속성을 설정하고 콘솔에서 얻은 API 키 값으로 설정해야 합니다."
"MistralAI 임베딩 모델에 대한 재시도 메커니즘을 구성하는 데 사용되는 속성 접두사는 무엇인가요?","MistralAI 임베딩 모델에 대한 재시도 메커니즘을 구성하는 데 사용되는 속성 접두사는 spring.ai.retry입니다."
"MistralAI 임베딩 모델의 공통 속성을 런타임에서 재정의하려면 어떻게 해야 하나요?","MistralAI 임베딩 모델의 공통 속성을 런타임에서 재정의하려면 EmbeddingRequest 호출에 요청별 런타임 옵션을 추가할 수 있습니다. 런타임 옵션은 MistralAiEmbeddingOptions.java(https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-mistral-ai/src/main/java/org/springframework/ai/mistralai/MistralAiEmbeddingOptions.java)에서 제공되며, 이는 모델 사용 등과 같은 MistralAI 구성을 포함합니다."
"스프링 생태계에서 미니맥스 언어 모델을 어떻게 사용할 수 있나요?","스프링 AI는 미니맥스의 다양한 AI 언어 모델을 지원합니다. 미니맥스 언어 모델과 상호 작용하고 미니맥스 모델을 기반으로 다국어 대화형 어시스턴트를 만들 수 있습니다. 이를 위해서는 먼저 미니맥스에서 API를 생성하여 미니맥스 언어 모델에 액세스해야 합니다. 미니맥스 등록 페이지(https://www.minimaxi.com/login)에서 계정을 만들고 API 키 페이지(https://www.minimaxi.com/user-center/basic-information/interface-key)에서 토큰을 생성해야 합니다. 스프링 AI 프로젝트는 spring.ai.minimax.api-key라는 구성 속성을 정의하며, 이 속성을 API 키 페이지(https://www.minimaxi.com/user-center/basic-information/interface-key)에서 얻은 API 키 값으로 설정해야 합니다. 환경 변수를 내보내는 것은 해당 구성 속성을 설정하는 한 가지 방법입니다. export SPRING_AI_MINIMAX_API_KEY=<INSERT KEY HERE>"
"스프링 AI에서 미니맥스 임베딩 모델에 대한 리트라이 메커니즘을 구성하는 방법은 무엇인가요?","스프링 AI는 Azure MiniMax 임베딩 모델에 대한 Spring Boot 자동 구성을 제공합니다. 이를 활성화하려면 프로젝트의 Maven pom.xml 파일에 다음 종속성을 추가하십시오: <dependency> <groupId>org.springframework.ai</groupId> <artifactId>spring-ai-minimax-spring-boot-starter</artifactId> </dependency> 또는 Gradle build.gradle 빌드 파일에 추가하십시오. dependencies { implementation 'org.springframework.ai:spring-ai-minimax-spring-boot-starter' } Spring AI BOM을 빌드 파일에 추가하려면 종속성 관리(../../getting-started.html#dependency-management) 섹션을 참조하십시오. 리트라이 메커니즘은 spring.ai.retry 접두사를 사용하여 구성할 수 있습니다. 이 접두사는 Maximum number of retry attempts, Initial sleep duration for the exponential backoff policy, Backoff interval multiplier, Maximum backoff duration, If false, throw a NonTransientAiException, and do not attempt retry for 4xx client error codes, List of HTTP status codes that should not trigger a retry, List of HTTP status codes that should trigger a retry 등의 속성을 포함합니다. 기본값은 10, 2 sec., 5, 3 min., false, empty, empty입니다."
"스프링 AI에서 미니맥스 임베딩 모델에 대한 연결 속성을 구성하는 방법은 무엇인가요?","스프링 AI는 Azure MiniMax 임베딩 모델에 대한 Spring Boot 자동 구성을 제공합니다. 이를 활성화하려면 프로젝트의 Maven pom.xml 파일에 다음 종속성을 추가하십시오: <dependency> <groupId>org.springframework.ai</groupId> <artifactId>spring-ai-minimax-spring-boot-starter</artifactId> </dependency> 또는 Gradle build.gradle 빌드 파일에 추가하십시오. dependencies { implementation 'org.springframework.ai:spring-ai-minimax-spring-boot-starter' } 종속성 관리(../../getting-started.html#dependency-management) 섹션을 참조하여 빌드 파일에 Spring AI BOM을 추가하십시오. 연결 속성은 spring.ai.minimax 접두사를 사용하여 구성할 수 있습니다. 이 접두사는 URL to connect to, The API Key 등의 속성을 포함합니다. 기본값은 api.minimax.chat(https://api.minimax.chat), Nothing입니다. spring.ai.minimax.base 및 spring.ai.minimax.api-key 속성은 런타임에 요청별 런타임 옵션(#embedding-options)을 임베딩 요청 호출에 추가하여 재정의할 수 있습니다. 또한, spring.ai.minimax.embedding.base 및 spring.ai.minimax.embedding.api-key 속성은 런타임에 요청별 런타임 옵션(#embedding-options)을 임베딩 요청 호출에 추가하여 재정의할 수 있습니다."
"OCI GenAI Embeddings란 무엇인가요?","OCI GenAI Embeddings는 온디맨드 모델 또는 전용 AI 클러스터와 함께 텍스트 임베딩을 제공하는 OCI GenAI 서비스입니다. (출처: https://docs.oracle.com/en-us/iaas/Content/generative-ai/embed-models.htm)"
"Spring AI OCI GenAI Embedding Client의 자동 구성을 사용하려면 어떻게 해야 하나요?","자동 구성을 사용하려면 프로젝트의 Maven pom.xml 또는 Gradle build.gradle 파일에 적절한 의존성을 추가하고 Spring AI BOM을 추가해야 합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/embeddings/oci-genai-embeddings.html)"
"OCI GenAI Embedding Properties는 어떤 역할을 하나요?","OCI GenAI Embedding Properties는 OCI GenAI에 대한 연결을 구성하는 데 사용되며, 인증 유형, 지역, 세입자 ID 및 사용자 ID와 같은 속성을 설정할 수 있습니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/embeddings/oci-genai-embeddings.html)"
"올라마 임베딩을 사용하려면 어떤 단계를 거쳐야 하나요?","올라마 임베딩을 사용하려면 먼저 로컬에서 올라마를 실행해야 합니다. 올라마 프로젝트 README(https://github.com/ollama/ollama)를 참조하여 로컬에서 모델을 실행하는 방법을 알아보세요."
"올라마 임베딩 모델의 Spring AI 자동 구성은 어떻게 작동하나요?","올라마 임베딩 모델의 Spring AI 자동 구성은 Maven pom.xml 파일에 다음 종속성을 추가하거나 Gradle build.gradle 빌드 파일에 종속성을 추가하여 활성화할 수 있습니다. Spring AI BOM을 빌드 파일에 추가하려면 Dependency Management(../../getting-started.html#dependency-management) 섹션을 참조하세요. Spring AI 아티팩트는 Spring Milestone 및 Snapshot 저장소에 게시됩니다. 빌드 시스템에 이러한 저장소를 추가하려면 Repositories 섹션을 참조하세요."
"올라마 임베딩 모델의 속성은 무엇인가요?","올라마 임베딩 모델의 속성은 spring.ai.ollama 접두사를 사용하여 구성할 수 있습니다. 이 속성에는 Ollama 임베딩 모델 자동 구성을 활성화하는 spring.ai.ollama.embedding.enabled, 사용할 지원되는 모델의 이름을 지정하는 spring.ai.ollama.embedding.options.model, 모델이 메모리에 로드된 후 유지되는 시간을 제어하는 spring.ai.ollama.embedding.options.keep_alive, 각 입력의 끝을 잘라내어 컨텍스트 길이 내에 맞추는 spring.ai.ollama.embedding.options.truncate 등이 포함됩니다. 나머지 옵션 속성은 Ollama 유효 매개 변수 및 값(https://github.com/ollama/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values) 및 Ollama 유형(https://github.com/ollama/ollama/blob/main/api/types.go)을 기반으로 합니다."
"Spring AI에서 Transformers Embedding Model은 무엇인가요?","선택한 sentence transformer를 사용하여 문장 임베딩을 로컬로 계산하는 EmbeddingModel 구현입니다. HuggingFace Embedding 모델 중 어떤 것이든 사용할 수 있습니다. 이는 Java에서 ONNX 모델을 실행하고 임베딩을 계산하기 위해 미리 훈련된 Transformer 모델을 Open Neural Network Exchange (ONNX) 형식으로 직렬화하여 사용합니다."
"Spring AI에서 ONNX Transformer Embedding Model을 활성화하려면 어떻게 해야 하나요?","프로젝트의 Maven pom.xml 또는 Gradle build.gradle 파일에 spring-ai-transformers-spring-boot-starter 종속성을 추가하여 활성화할 수 있습니다. 또한, spring.ai.embedding.transformer.* 속성을 사용하여 구성할 수 있습니다. 예를 들어, application.properties 파일에 다음을 추가하여 intfloat/e5-small-v2 텍스트 임베딩 모델을 사용하는 클라이언트를 구성할 수 있습니다: spring.ai.embedding.transformer.onnx.modelUri=https://huggingface.co/intfloat/e5-small-v2/resolve/main/model.onnx spring.ai.embedding.transformer.tokenizer.uri=https://huggingface.co/intfloat/e5-small-v2/raw/main/tokenizer.json"
"Spring AI에서 Transformers Embedding Model을 수동으로 구성하려면 어떻게 해야 하나요?","Spring Boot를 사용하지 않는 경우, 수동으로 TransformersEmbeddingModel을 구성할 수 있습니다. 이를 위해 spring-ai-transformers 종속성을 프로젝트의 Maven pom.xml 파일에 추가한 다음, 새로운 TransformersEmbeddingModel 인스턴스를 만들고 setTokenizerResource(tokenizerJsonUri) 및 setModelResource(modelOnnxUri) 메서드를 사용하여 내보낸 tokenizer.json 및 model.onnx 파일의 URI를 설정합니다. (classpath:, file: 또는 https: URI 스키마가 지원됩니다). 모델을 명시적으로 설정하지 않으면 TransformersEmbeddingModel은 sentence-transformers/all-MiniLM-L6-v2(https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)로 기본 설정됩니다."
"Spring AI에서 PostgresML 텍스트 임베딩 모델을 지원하는 이유는 무엇인가요?","Spring AI는 PostgresML 텍스트 임베딩 모델을 지원하여, 단어와 문장을 숫자 벡터로 표현하여 유사한 텍스트를 찾거나 다른 기계 학습 모델의 입력 특징으로 사용할 수 있습니다. 이는 텍스트를 직접 사용할 수 없는 대부분의 알고리즘에 유용합니다."
"Spring AI 아티팩트는 어떤 저장소에 게시되나요?","Spring AI 아티팩트는 Spring Milestone 및 Snapshot 저장소에 게시됩니다."
"PostgresML 임베딩 모델에 대한 Spring AI의 Spring Boot 자동 구성은 어떻게 사용하나요?","Spring AI의 Spring Boot 자동 구성을 사용하려면 프로젝트의 Maven pom.xml 또는 Gradle build.gradle 파일에 적절한 종속성을 추가하십시오. 그런 다음 spring.ai.postgresml.embedding.options.* 속성을 사용하여 모델에 대한 옵션을 구성하십시오."
"QianFan의 다양한 AI 언어 모델을 Spring AI에서 어떻게 상호작용하고 다국어 대화형 어시스턴트를 만들 수 있나요?","QianFan에서 API를 생성하여 QianFan 언어 모델에 액세스해야 합니다. QianFan 등록 페이지(https://login.bce.baidu.com/new-reg)에서 계정을 만들고 API 키 페이지(https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application)에서 토큰을 생성하세요. Spring AI 프로젝트는 spring.ai.qianfan.api-key 및 spring.ai.qianfan.secret-key라는 구성 속성을 정의합니다. API 키 페이지(https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application)에서 얻은 API 키 및 비밀 키의 값으로 설정해야 합니다. 환경 변수를 내보내는 것은 해당 구성 속성을 설정하는 한 가지 방법입니다: export SPRING_AI_QIANFAN_API_KEY=<INSERT KEY HERE>"
"QianFan에서 API를 생성하는 방법은 무엇인가요?","Baidu Cloud(https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application)에 로그인하고 'API Key' 버튼을 클릭하여 API를 생성할 수 있습니다. 그런 다음 API 키와 비밀 키를 복사하여 Spring AI 프로젝트의 구성 속성으로 사용할 수 있습니다."
"QianFan Embedding Client의 재시도 메커니즘을 구성하려면 어떻게 해야 하나요?","QianFan Embedding 클라이언트의 재시도 메커니즘을 구성하려면 spring.ai.retry 접두사를 사용하여 재시도 속성을 설정할 수 있습니다. 최대 재시도 시도 횟수를 지정하려면 spring.ai.retry.max-attempts 속성을 설정하세요. 지수 백오프 정책의 초기 대기 간격을 지정하려면 spring.ai.retry.backoff.initial-interval 속성을 설정하세요. 백오프 간격 배수를 지정하려면 spring.ai.retry.backoff.multiplier 속성을 설정하세요. 최대 백오프 기간을 지정하려면 spring.ai.retry.backoff.max-interval 속성을 설정하세요. 4xx 클라이언트 오류 코드에 대해 재시도를 시도하지 않고 NonTransientAiException을 throw하려면 spring.ai.retry.on-client-errors 속성을 false로 설정하세요. 재시도를 트리거하지 않아야 하는 HTTP 상태 코드 목록을 지정하려면 spring.ai.retry.exclude-on-http-codes 속성을 설정하세요. 재시도를 트리거해야 하는 HTTP 상태 코드 목록을 지정하려면 spring.ai.retry.on-http-codes 속성을 설정하세요."
"Spring AI의 VertexAI Embedding Model을 Spring Boot 프로젝트에서 사용하려면 어떤 단계를 따라야 하나요?","Spring AI의 VertexAI Embedding Model을 Spring Boot 프로젝트에서 사용하려면, 먼저 gcloud CLI를 설치하고 인증해야 합니다. 그런 다음, 빌드 시스템에 Spring AI 저장소를 추가하고 Spring AI BOM을 추가해야 합니다. 다음으로, Maven 또는 Gradle 의존성을 추가하여 Spring AI의 Spring Boot 자동 구성을 활성화합니다. 마지막으로, application.properties 파일에서 VertexAI Embedding API에 연결하기 위한 속성을 구성합니다."
"Spring AI의 VertexAI Embedding Model에서 어떤 속성을 사용할 수 있나요?","Spring AI의 VertexAI Embedding Model에서는 VertexAI Embedding API에 연결하기 위해 spring.ai.vertex.ai.embedding 속성 접두어를 사용합니다. 이 속성에는 project-id, location, apiEndpoint 등이 포함됩니다. VertexAI Text Embedding에 대한 임베딩 모델 구현을 구성하기 위해 spring.ai.vertex.ai.embedding.text 속성 접두어를 사용합니다. 이 속성에는 enabled, model, task-type 등이 포함됩니다."
"Spring AI의 VertexAI Embedding Model을 수동으로 구성하려면 어떻게 해야 하나요?","Spring AI의 VertexAI Embedding Model을 수동으로 구성하려면, 먼저 프로젝트 ID와 위치를 사용하여 VertexAiEmbeddigConnectionDetails를 생성합니다. 그런 다음, 모델 이름을 사용하여 VertexAiTextEmbeddingOptions를 생성합니다. 마지막으로, VertexAiEmbeddigConnectionDetails와 VertexAiTextEmbeddingOptions를 사용하여 VertexAiTextEmbeddingModel을 생성합니다."
"Google VertexAI Multimodal Embeddings는 어떤 용도로 사용되나요?","이미지, 텍스트 및 비디오 데이터의 조합을 기반으로 1408차원 벡터를 생성하여 이미지 분류 또는 비디오 콘텐츠 조정과 같은 후속 작업에 사용할 수 있습니다."
"Google VertexAI Multimodal Embeddings 모델은 어떤 제한 사항이 있나요?","VertexAI Multimodal API는 요청할 수 있는 동시 작업 수, 작업당 최대 크기 및 요청할 수 있는 최대 요청 수에 제한이 있습니다."
"Google VertexAI Multimodal Embeddings 모델에서 텍스트만 사용하는 경우 어떤 모델을 권장하나요?","Vertex AI 텍스트 임베딩 모델(vertexai-embeddings-text.html)을 사용하는 것이 좋습니다."
"Vertext AI의 PaLM2 임베딩을 사용하는 것이 어떤 경우에 적합한가요?","Vertext AI의 PaLM2 임베딩은 텍스트만 있는 임베딩 사용 사례에 적합합니다."
"PaLM API는 어떤 용도로 사용할 수 있나요?","PaLM API는 코드 생성, 추론, 작성 등 다양한 작업에 뛰어난 결과를 제공하는 PaLM 모델을 사용하여 생성형 AI 애플리케이션을 구축할 수 있습니다."
"PaLM2 REST API에 액세스하려면 어떤 전제 조건이 필요한가요?","PaLM2 REST API에 액세스하려면 makersuite에서 액세스 API KEY를 획득해야 합니다."
"Watsonx.ai를 사용하여 어떻게 임베딩을 생성할 수 있나요?","Watsonx.ai를 사용하여 임베딩을 생성하려면 SaaS 인스턴스와 IBM Cloud 계정이 필요합니다. WatsonxAiEmbeddingModel을 사용하여 Watsonx.ai 텍스트 임베딩을 사용할 수 있습니다. spring.ai.watsonx.embedding.options.* 속성을 사용하여 모든 임베딩 요청에 사용되는 기본 옵션을 구성할 수 있습니다. EmbeddingResponse embeddingResponse = embeddingModel.call(new EmbeddingRequest(List.of('Hello World', 'World is big and salvation is near'), WatsonxAiEmbeddingOptions.create().withModel('Different-Embedding-Model-Deployment-Name'))); Spring AI는 Watsonx.ai 임베딩 모델에 대한 Spring Boot 자동 구성도 제공합니다. - 출처: {https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/embeddings/watsonx-ai-embeddings.html}"
"Watsonx.ai 임베딩 모델을 사용하려면 어떤 의존성을 추가해야 하나요?","Maven pom.xml 파일에서 <dependency> <groupId>org.springframework.ai</groupId> <artifactId>spring-ai-watsonx-ai-spring-boot-starter</artifactId> </dependency>를 추가하거나 Gradle build.gradle 빌드 파일에서 dependencies { implementation 'org.springframework.ai:spring-ai-watsonx-ai-spring-boot-starter' }를 추가하여 Watsonx.ai 임베딩 모델을 사용할 수 있습니다. Spring AI BOM을 빌드 파일에 추가하여 종속성 관리를 용이하게 할 수 있습니다. - 출처: {https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/embeddings/watsonx-ai-embeddings.html}"
"임베딩 프로세스 중에 사용될 모델을 구성하려면 어떤 속성을 사용해야 하나요?","임베딩 프로세스 중에 사용될 모델을 구성하기 위해 spring.ai.watsonx.ai.embedding.options.model 속성을 사용할 수 있습니다. default 값은 ibm/slate-30m-english-rtrvr입니다. WatsonxAiEmbeddingOptions.java를 사용하여 이를 구성할 수 있습니다. - 출처: {https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/embeddings/watsonx-ai-embeddings.html}"
"ZhiPuAI 임베딩은 무엇인가요?","ZhiPuAI의 텍스트 임베딩 모델은 텍스트 문자열의 관련성을 측정합니다. 임베딩은 부동 소수점 숫자의 벡터(리스트)입니다. 두 벡터 간의 거리는 관련성을 측정합니다. 작은 거리는 높은 관련성을 시사하고 큰 거리는 낮은 관련성을 시사합니다."
"ZhiPuAI 임베딩 모델을 사용하려면 어떤 사전 요구 사항이 있나요?","ZhiPuAI와 API를 생성하여 ZhiPuAI 언어 모델에 액세스해야 합니다. ZhiPu AI 등록 페이지(https://open.bigmodel.cn/login)에서 계정을 만들고 API 키 페이지(https://open.bigmodel.cn/usercenter/apikeys)에서 토큰을 생성하세요."
"Spring AI 프로젝트에서 ZhiPuAI 임베딩 모델의 최대 재시도 횟수를 구성하려면 어떻게 해야 하나요?","spring.ai.retry.max-attempts 구성 속성을 사용하여 ZhiPuAI 임베딩 모델의 최대 재시도 횟수를 구성할 수 있습니다. 기본값은 10입니다."
"Azure OpenAI 서비스에서 DALL-E를 사용하려면 Spring AI에서 어떤 구성 속성을 설정해야 하나요?","spring.ai.azure.openai.api-key 및 spring.ai.azure.openai.endpoint"
"Azure AI Deployment를 생성하여 Azure AI 애플리케이션을 사용하는 방법은 무엇인가요?","Azure AI 포털(https://oai.azure.com/portal)을 통해 생성합니다."
"Azure OpenAI Chat Client의 자동 구성을 활성화하려면 Spring Boot 프로젝트에 어떤 종속성을 추가해야 하나요?","<dependency><groupId>org.springframework.ai</groupId><artifactId>spring-ai-azure-openai-spring-boot-starter</artifactId></dependency>"
"Spring AI에서 OpenAI와 연결하기 위해 사용되는 속성 접두사는 무엇인가요?","spring.ai.openai (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/image/openai-image.html>)"
"Spring AI OpenAI Image Generation Client를 활성화하는 방법은 무엇인가요?","프로젝트의 Maven pom.xml 파일에 <dependency> <groupId>org.springframework.ai</groupId> <artifactId>spring-ai-openai-spring-boot-starter</artifactId> </dependency> 또는 Gradle build.gradle 빌드 파일에 dependencies { implementation 'org.springframework.ai:spring-ai-openai-spring-boot-starter' }를 추가하세요. 빌드 파일에 Spring AI BOM을 추가하려면 Dependency Management(../../getting-started.html#dependency-management) 섹션을 참조하세요. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/image/openai-image.html>)"
"Spring AI OpenAI Image Generation을 위해 설정해야 하는 필수 환경 변수는 무엇인가요?","SPRING_AI_OPENAI_API_KEY (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/image/openai-image.html>)"
"Stability AI와 연동하기 위해 필요한 전제 조건은 무엇인가요?","Stability AI의 AI 모델에 접근하기 위해 API 키를 생성해야 하며, Stability AI의 Getting Started 문서를 따라야 합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/image/stabilityai-image.html)"
"Stability AI Image Generation Client에 대한 Spring AI의 Spring Boot auto-configuration을 활성화하려면 어떻게 해야 하나요?","프로젝트의 Maven pom.xml 또는 Gradle build.gradle 파일에 다음 의존성을 추가하면 됩니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/image/stabilityai-image.html)"
"Stability AI의 ImageModel 구현을 구성하기 위한 속성 접두사는 무엇인가요?","spring.ai.stabilityai.image입니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/image/stabilityai-image.html)"
"ZhiPuAI를 사용하여 이미지 생성을 지원하는 Spring AI 기능은 무엇인가요?","CogView"
"ZhiPuAI 이미지 모델에 액세스하려면 어떤 사전 요구 사항이 필요한가요?","ZhiPuAI에서 API를 생성해야 합니다."
"Spring AI 프로젝트에서 ZhiPuAI API 키를 설정하는 방법은 무엇인가요?","export SPRING_AI_ZHIPU_AI_API_KEY=<INSERT KEY HERE>"
"QianFan Image Generation을 사용하려면 어떤 사전 요구 사항이 필요한가요?","QianFan Image Generation을 사용하려면 QianFan에서 API를 생성하여 QianFan 언어 모델에 액세스해야 합니다. QianFan 등록 페이지(https://login.bce.baidu.com/new-reg)에서 계정을 만들고 API 키 페이지(https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application)에서 토큰을 생성해야 합니다."
"Spring AI는 QianFan Image Generation을 어떻게 구성할 수 있나요?","Spring AI는 QianFan Image Generation을 구성하기 위해 spring.ai.qianfan.image 접두사를 사용합니다. 이 접두사를 사용하여 QianFan의 ImageModel 구현을 구성할 수 있는 속성 접두사를 제공합니다."
"QianFan Image Generation을 사용하기 위해 Spring AI에 필요한 종속성은 무엇인가요?","QianFan Image Generation을 사용하기 위해 Spring AI에 필요한 종속성은 spring-ai-qianfan-spring-boot-starter입니다. 이 종속성은 Maven pom.xml 파일 또는 Gradle build.gradle 빌드 파일에 추가하여 프로젝트에 포함시킬 수 있습니다. 또한 Spring AI BOM을 추가하여 프로젝트 전체에서 일관된 버전의 Spring AI를 사용할 수 있도록 해야 합니다."
"Spring AI 프로젝트의 목적은 무엇인가요?","Spring AI 프로젝트는 인공지능 기능을 불필요한 복잡성 없이 통합하는 애플리케이션 개발을 간소화하는 것을 목표로 합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/index.html#api/audio)"
"Spring AI는 Python 프로젝트인 LangChain과 LlamaIndex와 어떤 관련이 있나요?","Spring AI 프로젝트는 Python 프로젝트인 LangChain과 LlamaIndex에서 영감을 받았지만, 해당 프로젝트들을 직접 이식한 것은 아닙니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/index.html#api/audio)"
"Spring AI는 어떤 AI 모델 제공업체와 벡터 데이터베이스 제공업체를 지원하나요?","Spring AI는 OpenAI, Microsoft, Amazon, Google, Hugging Face와 같은 주요 모델 제공업체와 Apache Cassandra, Azure Vector Search, Chroma, Milvus, MongoDB Atlas, Neo4j, Oracle, PostgreSQL/PGVector, PineCone, Qdrant, Redis, Weaviate와 같은 주요 벡터 데이터베이스 제공업체를 지원합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/index.html#api/audio)"
"Spring AI는 어떤 Transcription API를 지원하나요?","OpenAI의 Transcription API를 지원합니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/audio/transcriptions.html>)"
"Spring AI에서 다른 Transcription 제공업체를 구현할 때 어떤 일이 발생하나요?","공통 AudioTranscriptionModel 인터페이스가 추출됩니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/audio/transcriptions.html>)"
"Spring AI의 Transcription API에 관련된 추가 제공업체를 어디에서 찾을 수 있나요?","QianFan과 Azure OpenAI는 추가 제공업체입니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/audio/transcriptions.html>)"
"OpenAI Transcriptions를 사용하려면 어떤 사전 요구 사항이 필요한가요?","OpenAI Transcriptions를 사용하려면 OpenAI에서 API 키를 생성하고, 해당 API 키를 spring.ai.openai.api-key 구성 속성에 설정해야 합니다. OpenAI 가입 페이지(https://platform.openai.com/signup)에서 계정을 생성하고, API 키 페이지(https://platform.openai.com/account/api-keys)에서 토큰을 생성할 수 있습니다."
"Spring AI에서 OpenAI Transcription Client에 대한 자동 구성을 사용하려면 어떻게 해야 하나요?","Spring AI에서 OpenAI Transcription Client에 대한 자동 구성을 사용하려면 프로젝트의 Maven pom.xml 파일 또는 Gradle build.gradle build 파일에 spring-ai-openai-spring-boot-starter 종속성을 추가하고, 빌드 파일에 Spring AI BOM을 포함해야 합니다."
"OpenAI Transcription Client를 수동으로 구성하려면 어떻게 해야 하나요?","OpenAI Transcription Client를 수동으로 구성하려면 프로젝트의 Maven pom.xml 파일 또는 Gradle build.gradle build 파일에 spring-ai-openai 종속성을 추가하고, OpenAiAudioApi 및 OpenAiAudioTranscriptionModel 클래스를 사용하여 OpenAI API와 연결하고, OpenAiAudioTranscriptionOptions 클래스를 사용하여 트랜스크립션 옵션을 구성해야 합니다."
"Spring AI는 어떤 TTS(Text-To-Speech) API를 지원하나요?","OpenAI의 Speech API를 지원합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/audio/speech.html)"
"Spring AI는 Speech API를 위해 다른 제공업체와 어떻게 통합될 예정인가요?","추가적인 Speech 제공업체가 구현될 때, 공통의 SpeechModel 및 StreamingSpeechModel 인터페이스가 추출될 예정입니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/audio/speech.html)"
"OpenAI의 Speech API에 대한 Spring AI의 문서는 어디에서 찾을 수 있나요?","해당 문서는 다음 링크에서 확인할 수 있습니다: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/audio/speech.html"
"Spring AI 프로젝트의 주요 목표는 무엇인가요?","Spring AI 프로젝트의 주요 목표는 불필요한 복잡성 없이 인공지능 기능을 통합하는 애플리케이션의 개발을 간소화하는 것입니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/index.html#api/moderation)"
"Spring AI는 어떤 프로그래밍 언어에서 사용할 수 있나요?","Spring AI는 Python뿐만 아니라 다양한 프로그래밍 언어에서 사용할 수 있도록 설계되었습니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/index.html#api/moderation)"
"Spring AI 프로젝트에서 어떤 AI 모델 제공업체를 지원하나요?","Spring AI 프로젝트는 OpenAI, Microsoft, Amazon, Google, Hugging Face와 같은 주요 모델 제공업체를 지원합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/index.html#api/moderation)"
"Spring AI에서 OpenAI의 Moderation 모델을 어떻게 사용할 수 있나요?","OpenAI 계정을 만들고 API 키를 얻은 후, 프로젝트의 빌드 파일에 spring-ai-openai 종속성을 추가하고 OpenAI Text-to-Speech Client에 대한 Spring AI 자동 구성을 활성화하세요. 그런 다음 OpenAiModerationModel을 만들고 call 메서드를 사용하여 Moderation 결과를 검색하세요. spring.ai.openai.moderation 접두사를 사용하여 OpenAI Moderation 모델을 구성하고 런타임에서 OpenAiModerationOptions 클래스를 사용하여 옵션을 재정의할 수 있습니다. https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/moderation/openai-moderation.html"
"Spring AI에서 OpenAI Moderation 모델의 런타임 옵션을 어떻게 재정의하나요?","OpenAiModerationOptions 클래스를 사용하여 Moderation 요청을 할 때 사용할 옵션을 제공합니다. 시작 시 spring.ai.openai.moderation에 지정된 옵션을 사용하지만 런타임에서 이를 재정의할 수 있습니다. OpenAiModerationOptions 객체를 만들고 원하는 속성을 설정한 다음 ModerationPrompt를 만들고 call 메서드를 사용하여 ModerationResponse를 검색하세요. 그런 다음 ModerationResponse의 getResult() 메서드를 사용하여 Moderation 객체에 액세스하고 다양한 get 메서드를 사용하여 다양한 필드에 액세스하세요. https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/moderation/openai-moderation.html"
"Spring AI에서 OpenAI Moderation 모델을 수동으로 구성하려면 어떻게 해야 하나요?","프로젝트의 Maven pom.xml 또는 Gradle build.gradle 파일에 spring-ai-openai 종속성을 추가하고 OpenAiModerationApi 객체를 만들어 API 키를 전달하세요. 그런 다음 OpenAiModerationModel 객체를 만들고 OpenAiModerationOptions 객체를 만들고 원하는 속성을 설정한 다음 ModerationPrompt 객체를 만들고 call 메서드를 사용하여 ModerationResponse를 검색하세요. 그런 다음 ModerationResponse의 getResult() 메서드를 사용하여 Moderation 객체에 액세스하고 다양한 get 메서드를 사용하여 다양한 필드에 액세스하세요. https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/moderation/openai-moderation.html"
"벡터 데이터베이스란 무엇이며 어떤 역할을 하는가?","벡터 데이터베이스는 AI 애플리케이션에서 필수적인 역할을 하는 특수한 유형의 데이터베이스입니다. 벡터 데이터베이스에서는 쿼리가 전통적인 관계형 데이터베이스와 달리 정확한 일치가 아닌 유사도 검색을 수행합니다. 벡터 데이터베이스는 데이터를 AI 모델과 통합하기 위해 사용되며, 벡터 데이터베이스에서 쿼리로 벡터를 제공하면 쿼리 벡터와 '유사한' 벡터를 반환합니다. 자세한 내용은 Vector Similarity(vectordbs/understand-vectordbs.html#vectordbs-similarity)에서 제공됩니다."
"Spring AI의 VectorStore 인터페이스와 관련된 클래스는 무엇인가요?","Spring AI의 VectorStore 인터페이스와 관련된 클래스는 VectorStore 인터페이스 자체와 SearchRequest 빌더입니다. VectorStore 인터페이스 정의는 다음과 같습니다: public interface VectorStore { void add(List<Document> documents); Optional<Boolean> delete(List<String> idList); List<Document> similaritySearch(String query); List<Document> similaritySearch(SearchRequest request); } 그리고 관련된 SearchRequest 빌더: public class SearchRequest { public final String query; private int topK = 4; private double similarityThreshold = SIMILARITY_THRESHOLD_ALL; private Filter.Expression filterExpression; public static SearchRequest query(String query) { return new SearchRequest(query); } private SearchRequest(String query) { this.query = query; } public SearchRequest withTopK(int topK) {...} public SearchRequest withSimilarityThreshold(double threshold) {...} public SearchRequest withSimilarityThresholdAll() {...} public SearchRequest withFilterExpression(Filter.Expression expression) {...} public SearchRequest withFilterExpression(String textExpression) {...} public String getQuery() {...} public int getTopK() {...} public double getSimilarityThreshold() {...} public Filter.Expression getFilterExpression() {...} }"
"벡터 데이터베이스에서 데이터를 삽입하려면 어떻게 해야 하나요?","벡터 데이터베이스에 데이터를 삽입하려면 Document 객체 내에 데이터를 캡슐화해야 합니다. Document 클래스는 PDF 또는 Word 문서와 같은 데이터 소스의 내용을 캡슐화하고 문자열로 표현된 텍스트와 함께 메타데이터를 키-값 쌍으로 포함합니다. 벡터 데이터베이스에 삽입하면 텍스트 내용이 임베딩 모델을 사용하여 벡터 임베딩이라고 하는 숫자 배열 또는 float[]로 변환됩니다. 임베딩 모델은 Word2Vec, GLoVE, BERT 또는 OpenAI의 text-embedding-ada-002와 같은 것으로, 단어, 문장 또는 단락을 이러한 벡터 임베딩으로 변환하는 데 사용됩니다."
"Azure Search Service는 어떤 목적으로 사용되나요?","Azure AI Search Service는 Microsoft의 AI 플랫폼 중 하나로, 문서 임베딩을 저장하고 유사도 검색을 수행하기 위한 Azure VectorStore를 설정하는 데 사용됩니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/azure.html)"
"Azure VectorStore를 설정하기 위해 필요한 사전 요구 사항은 무엇인가요?","Azure VectorStore를 설정하기 위해 필요한 사전 요구 사항은 Azure 구독과 Azure AI Search Service입니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/azure.html)"
"Azure VectorStore를 설정하는 데 필요한 구성 속성은 어떤 것이 있나요?","Azure VectorStore를 설정하는 데 사용할 수 있는 구성 속성은 spring.ai.vectorstore.azure.api-key, spring.ai.vectorstore.azure.initialize-schema, spring.ai.vectorstore.azure.index-name, spring.ai.vectorstore.azure.default-top-k, spring.ai.vectorstore.azure.default-similarity-threshold, spring.ai.vectorstore.azure.embedding-property, spring.ai.vectorstore.azure.index-name 등이 있습니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/azure.html)"
"아파치 카산드라는 어떤 용도로 사용되는 분산 데이터베이스인가요?","아파치 카산드라는 선형 확장성, 검증된 내결함성 및 낮은 지연 시간을 갖춘 진정한 오픈 소스 분산 데이터베이스로, 중요한 트랜잭션 데이터에 적합한 플랫폼입니다."
"JVector는 다른 HNSW Vector Similarity Search 구현과 비교하여 어떤 점에서 뛰어난가요?","JVector는 알고리즘적으로 빠르며, DiskANN 및 관련 연구에서 영감을 받은 최신 그래프 알고리즘을 사용하여 높은 재현율과 낮은 지연 시간을 제공합니다. 또한 구현이 빠르고, 메모리를 효율적으로 사용하며, 쉽게 포함시킬 수 있는 API를 제공합니다."
"DocumentStore를 사용하여 RAG 애플리케이션에 필요한 종속성을 어떻게 추가하나요?","DocumentStore를 사용하여 RAG 애플리케이션에 필요한 종속성을 추가하려면, 프로젝트에 다음 종속성을 추가해야 합니다: spring-ai-cassandra-store 또는 spring-ai-cassandra-store-spring-boot-starter. 또한 Spring AI BOM을 빌드 파일에 추가하려면 종속성 관리 섹션을 참조하십시오."
"Spring AI에서 Elasticsearch Vector Store를 설정하기 위한 전제 조건은 무엇인가요?","Spring AI에서 Elasticsearch Vector Store를 설정하기 위한 전제 조건은 실행 중인 Elasticsearch 인스턴스입니다."
"Elasticsearch를 사용하기 위해 추가해야 하는 의존성은 무엇인가요?","Elasticsearch를 사용하기 위해 추가해야 하는 의존성은 <dependency> <groupId>org.springframework.ai</groupId> <artifactId>spring-ai-elasticsearch-store-spring-boot-starter</artifactId> </dependency>입니다."
"Elasticsearch Vector Store를 수동으로 구성하려면 어떤 의존성을 추가해야 하나요?","Elasticsearch Vector Store를 수동으로 구성하려면 <dependency> <groupId>org.springframework.ai</groupId> <artifactId>spring-ai-elasticsearch-store</artifactId> </dependency>를 추가해야 합니다."
"GemFire VectorDB는 무엇인가요?","GemFire VectorDB는 GemFire의 기능을 확장한 것으로, 효율적인 벡터 저장, 검색 및 벡터 유사도 검색을 수행하는 다목적 벡터 데이터베이스입니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/gemfire.html>)"
"GemFire VectorStore를 Spring Boot 프로젝트에 구성하려면 어떻게 해야 하나요?","GemFire VectorStore Spring Boot 스타터를 프로젝트의 Maven build 파일 pom.xml 또는 Gradle build.gradle 파일에 추가하고, 구성 속성을 사용하여 GemFireVectorStore를 추가로 구성할 수 있습니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/gemfire.html>)"
"GemFire VectorStore를 사용하여 유사도 검색을 수행하려면 어떻게 해야 하나요?","먼저, VectorStore 인터페이스를 구현하는 GemfireVectorStore 인스턴스를 만듭니다. 그런 다음, 문서를 저장하고 SimilaritySearchRequest 객체를 사용하여 유사도 검색을 수행할 수 있습니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/gemfire.html>)"
"밀루스는 어떤 종류의 데이터베이스인가요?","밀루스는 벡터 데이터베이스로, 데이터 과학과 기계 학습 분야에서 사용됩니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/milvus.html)"
"밀루스에서 사용 가능한 인덱스 유형은 무엇인가요?","밀루스에서는 IVF_FLAT, IVF_SQ8, IVF_HNSW 세 가지 인덱스 유형을 사용할 수 있습니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/milvus.html)"
"밀루스 벡터스토어에서 사용할 수 있는 메트릭 유형은 무엇인가요?","밀루스 벡터스토어에서는 COSINE, L2, IP 메트릭 유형을 사용할 수 있습니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/milvus.html)"
"Spring AI에서 MongoDB Atlas를 벡터 스토어로 설정하는 방법은 무엇인가요?","Spring AI에서 MongoDB Atlas를 벡터 스토어로 설정하려면, MongoDB Atlas를 구성하고, 문서 임베딩을 계산하기 위한 EmbeddingModel 인스턴스를 만들고, Java 애플리케이션을 설정할 환경을 마련해야 합니다. 또한, Spring AI의 Spring Boot 자동 설정을 활성화하기 위해 프로젝트의 빌드 파일에 적절한 종속성을 추가해야 합니다. 또한, 적절한 생성자에서 initializeSchema 부울 값을 지정하거나 application.properties 파일에서 spring.ai.vectorstore.mongodb.initialize-schema=true를 설정하여 필요한 스키마를 초기화할 수 있습니다. 스키마 초기화를 위해 Spring AI BOM을 빌드 파일에 추가해야 하며, Milestone 및/또는 Snapshot 저장소를 빌드 파일에 추가해야 합니다."
"Spring AI MongoDB Atlas 벡터 스토어에서 스키마를 수동으로 구성하려면 어떻게 해야 하나요?","Spring AI MongoDB Atlas 벡터 스토어에서 스키마를 수동으로 구성하려면, MongoDBAtlasVectorStore 및 해당 종속성을 직접 설정하여 자동 설정 없이 구성할 수 있습니다. MongoDBAtlasVectorStore와 함께 MongoTemplate 및 EmbeddingModel 인스턴스를 사용하여 벡터 스토어를 구성할 수 있습니다. 또한, MongoDBAtlasVectorStoreConfig 객체를 사용하여 벡터 저장소의 컬렉션 이름, 벡터 인덱스 이름, 벡터 저장되는 경로, 필터링할 메타데이터 필드 등 다양한 구성 속성을 구성할 수 있습니다."
"Spring AI MongoDB Atlas 벡터 스토어에서 쿼리 시 메타데이터 필터링을 어떻게 수행하나요?","Spring AI MongoDB Atlas 벡터 스토어에서 쿼리 시 메타데이터 필터링을 수행하려면, MongoDBAtlasFilterExpressionConverter 클래스를 사용하여 필터 표현을 MongoDB Atlas 메타데이터 필터 표현으로 변환할 수 있습니다. 지원되는 작업에는 $and, $or, $eq, $ne, $lt, $lte, $gt, $gte, $in, $nin이 포함됩니다. 이러한 연산자를 사용하여 벡터 검색과 함께 문서와 연결된 메타데이터 필드에 필터링 로직을 적용할 수 있습니다. 예를 들어, $eq 연산자를 사용하여 'author' 필드가 'A'인 검색 결과를 필터링할 수 있습니다."
"Neo4j는 어떤 종류의 데이터베이스인가요?","Neo4j는 오픈 소스 NoSQL 그래프 데이터베이스입니다."
"Neo4j에서 인덱싱은 어떻게 이루어지나요?","Neo4j의 벡터 검색은 Lucene을 사용하여 Hierarchical Navigable Small World Graph (HNSW)를 통해 벡터 필드에 대한 k 근사 이웃 (k-ANN) 쿼리를 수행합니다."
"Neo4jVectorStore에서 임베딩 차원을 설정하는 방법은 무엇인가요?","Spring Boot 구성에서 spring.ai.vectorstore.neo4j.embedding-dimension 속성을 사용하여 임베딩 차원을 설정할 수 있습니다."
"엘라스틱서치에서 포크된 오픈소스 검색 및 분석 엔진은 무엇인가요?","오픈서치(OpenSearch)입니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/opensearch.html)"
"오픈서치는 어떤 라이선스로 배포되나요?","아파치 라이선스 2.0으로 배포됩니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/opensearch.html)"
"오픈서치는 어떤 유형의 검색 기능을 지원하나요?","벡터, 어휘 및 하이브리드 검색 기능을 지원합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/opensearch.html)"
"Spring AI Oracle VectorStore를 사용하여 데이터베이스에 연결하고 구성하는 방법은 무엇인가요?","OracleVectorStore를 연결하고 구성하려면 데이터베이스에 대한 액세스 세부 정보를 제공해야 합니다. 간단한 구성은 Spring Boot의 application.yml 또는 application.properties 파일에서 다음과 같이 제공할 수 있습니다: spring.datasource.url: jdbc:oracle:thin:@//localhost:1521/freepdb1, spring.datasource.username: mlops, spring.datasource.password: mlops, ai.vectorstore.oracle.index-type: IVF, ai.vectorstore.oracle.distance-type: COSINE, ai.vectorstore.oracle.dimensions: 1536 (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/oracle.html)"
"Spring AI Oracle VectorStore에서 스키마를 초기화하는 방법은 무엇인가요?","OracleVectorStore에서 스키마를 초기화하려면 initializeSchema 매개변수를 true로 설정하거나 application.properties 파일에서 initialize-schema=true로 설정해야 합니다. 스키마 초기화는 이제 기본적으로 발생하지 않으며, 필요한 경우에만 수행해야 하는 breaking change입니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/oracle.html)"
"Spring AI Oracle VectorStore에서 사용 가능한 구성을 구성하는 방법은 무엇인가요?","Spring AI Oracle VectorStore에서 사용 가능한 구성은 spring.ai.vectorstore.oracle.index-type, spring.ai.vectorstore.oracle.distance-type, spring.ai.vectorstore.oracle.dimensions와 같은 Spring Boot 구성 속성을 사용하여 사용자 지정할 수 있습니다. 이러한 속성의 기본값 및 구성 옵션에 대한 자세한 내용은 https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/oracle.html을 참조하십시오. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/oracle.html)"
"PGvector를 사용하여 벡터 임베딩을 저장하고 유사도 검색을 수행하려면 어떤 단계를 거쳐야 하나요?","PostgreSQL 인스턴스에 액세스하고 vector, hstore 및 uuid-ossp 확장을 활성화한 다음, Docker Compose 또는 Testcontainers를 통해 Spring Boot dev 서비스로 PGvector 데이터베이스를 실행하거나 Docker 컨테이너를 사용하여 로컬에서 DB를 설정할 수 있습니다. 시작 시 PgVectorStore는 필요한 데이터베이스 확장을 설치하고 필요한 vector_store 테이블과 인덱스를 생성하려고 시도합니다. 필요한 경우 수동으로 수행할 수도 있으며, 쿼리에서 사용할 임베딩 모델을 위한 API 키를 가져와야 합니다."
"PGVector를 사용하여 PgVectorStore를 구성하려면 어떻게 해야 하나요?","Spring Boot의 application.yml을 통해 간단한 구성을 제공하거나 Spring Boot 자동 구성을 사용하지 않고 PgVectorStore를 수동으로 구성할 수 있습니다. 수동으로 구성하려면 PostgreSQL 연결 및 JdbcTemplate 자동 구성 종속성을 프로젝트에 추가해야 합니다."
"PGVector의 구성 매개 변수를 어떻게 사용자 지정할 수 있나요?","Spring Boot 구성에서 다음 매개 변수를 사용하여 PGVector 벡터 저장소를 사용자 지정할 수 있습니다. index-type, distance-type, dimensions, remove-existing-vector-store-table, initialize-schema, schema-name 및 table-name입니다. 또한 spring.ai.vectorstore.pgvector.schema-validation을 true로 설정하여 스키마 및 테이블 이름 유효성 검사를 활성화할 수 있습니다."
"Pinecone VectorStore를 사용하기 위해 필요한 사전 요구 사항은 무엇인가요?","Pinecone 계정과 새로운 프로젝트, 인덱스를 생성하고 API 키를 생성해야 합니다."
"Pinecone VectorStore를 구성하기 위해 어떤 방법이 있나요?","Spring AI는 Pinecone Vector Store에 대한 Spring Boot 자동 구성을 제공합니다. 또는 PineconeVectorStoreConfig 빈을 만들고 PineconeVectorStore 생성자에 전달하여 수동으로 구성할 수 있습니다."
"Pinecone VectorStore에서 사용할 수 있는 구성 속성은 무엇인가요?","Pinecone API 키, 환경, 프로젝트 ID, 인덱스 이름 및 콘텐츠 필드 이름과 같은 속성을 구성할 수 있습니다."
"QdrantVectorStore를 사용하기 위해 어떤 요구사항이 필요한가요?","QdrantVectorStore를 사용하려면 Qdrant 인스턴스를 설치하고, 호스트, GRPC 포트, 컬렉션 이름, 그리고 필요한 경우 API 키와 같은 정보를 제공해야 합니다. 또한, 적절한 차원과 구성으로 Qdrant 컬렉션을 미리 생성하는 것이 좋습니다. 또한, 문서의 임베딩을 계산하기 위해 EmbeddingModel 인스턴스가 필요합니다."
"Qdrant 인스턴스에 연결하기 위해 어떻게 구성해야 하나요?","Spring Boot의 application.properties 파일을 사용하여 Qdrant 인스턴스에 대한 액세스 세부 정보를 제공해야 합니다. 제공해야 하는 속성에는 host, port, api-key, collection-name이 포함됩니다. 또한, TLS를 사용할지 여부를 구성할 수 있습니다."
"QdrantVectorStore에서 사용 가능한 속성은 어떤 것이 있나요?","Qdrant vector store를 사용자 정의하기 위해 host, port, api-key, collection-name, use-tls, initialize-schema 등의 속성을 사용할 수 있습니다. 이러한 속성은 기본값과 구성 옵션을 포함하여 Spring Boot 구성에서 설명되어 있습니다."
"RedisVectorStore에서 Redis는 어떤 용도로 사용되나요?","Redis는 문서의 임베딩을 저장하고 유사도 검색을 수행하는 데 사용됩니다."
"RedisVectorStore를 설정하기 위한 전제 조건은 무엇인가요?","RedisStack 인스턴스, 임베딩 모델을 계산하는 임베딩 모델 인스턴스, 그리고 필요한 경우 임베딩을 생성하기 위한 임베딩 모델의 API 키가 필요합니다."
"Spring AI는 Redis Vector Store 설정에 대한 자동 구성을 제공하나요?","네, Spring AI는 Redis Vector Store 설정에 대한 Spring Boot 자동 구성을 제공합니다."
"SAP HANA Cloud 벡터 엔진에서 벡터 저장소를 구성하려면 어떤 속성을 사용해야 하나요?","spring.datasource.driver-class-name, spring.datasource.url, spring.datasource.username, spring.datasource.password, spring.ai.vectorstore.hanadb.top-k, spring.ai.vectorstore.hanadb.table-name, spring.ai.vectorstore.hanadb.initialize-schema 속성을 사용할 수 있습니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/hana.html)"
"SAP HANA Cloud 벡터 저장소를 Spring Boot 프로젝트에 구성하려면 어떤 종속성을 추가해야 하나요?","spring-ai-hanadb-store-spring-boot-starter 종속성을 추가할 수 있습니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/hana.html)"
"SAP HANA Cloud 벡터 저장소를 사용하여 Spring AI에서 RAG 애플리케이션을 구현하려면 어떻게 해야 하나요?","SAP HANA Cloud를 벡터 DB로 사용하고 OpenAI를 활용하여 RAG 패턴을 구현하는 프로젝트를 설정하고, CRICKET_WORLD_CUP 테이블을 생성하고, pom.xml에 필요한 종속성을 추가하고, application.properties 파일에 속성을 추가하고, CricketWorldCup 엔티티 클래스와 CricketWorldCupRepository 리포지토리 인터페이스를 구현하고, REST 컨트롤러 클래스를 생성하여 REST 엔드포인트를 정의해야 합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/hana.html)"
"Weaviate는 무엇인가요?","Weaviate는 오픈 소스 벡터 데이터베이스로, 데이터 객체와 ML 모델의 벡터 임베딩을 저장하고 수십억 개의 데이터 객체로 원활하게 확장할 수 있습니다. 문서 임베딩, 콘텐츠 및 메타데이터를 저장하고 메타데이터 필터를 포함한 이러한 임베딩을 검색하는 도구를 제공합니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/weaviate.html>)"
"WeaviateVectorStore를 사용하기 위한 전제 조건은 무엇인가요?","WeaviateVectorStore를 사용하기 위한 전제 조건은 문서 임베딩을 계산하기 위한 EmbeddingModel 인스턴스입니다. Transformers Embedding, OpenAI Embedding, Azure OpenAI Embedding 또는 PostgresML Embedding Model과 같은 여러 옵션이 있습니다. 또한 Weaviate 클러스터가 필요하며, Docker 컨테이너에서 로컬로 클러스터를 설정하거나 Weaviate Cloud Service를 만들 수 있습니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/weaviate.html>)"
"WeaviateVectorStore를 Spring Boot 애플리케이션에 수동으로 구성하려면 어떻게 해야 하나요?","Spring Boot 자동 구성을 사용하는 대신 WeaviateVectorStore를 수동으로 구성하려면 프로젝트에 spring-ai-weaviate-store 종속성을 추가해야 합니다. 그런 다음 WeaviateClient를 만들고 사용자 정의 WeaviateVectorStoreConfig 객체를 사용하여 WeaviateVectorStore를 구성할 수 있습니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/vectordbs/weaviate.html>)"
"Spring AI에서 어떤 AI 모델들이 기능 호출을 지원하나요?","Anthropic Claude, Azure OpenAI, Google VertexAI Gemini, Groq, Mistral AI, Ollama, OpenAI가 Spring AI에서 기능 호출을 지원합니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/functions.html>)"
"Anthropic Claude의 기능 호출에 대한 자세한 문서는 어디에 있나요?","Anthropic Claude의 기능 호출에 대한 자세한 문서는 Anthropic Claude 기능 호출 문서(chat/functions/anthropic-chat-functions.html)에서 확인할 수 있습니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/functions.html>)"
"Ollama의 기능 호출은 스트리밍을 지원하나요?","아니요, 현재 Ollama의 기능 호출은 스트리밍을 지원하지 않습니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/functions.html>)"
"Spring AI에서 멀티모달리티란 무엇인가요?","Spring AI에서 멀티모달리티는 텍스트, 이미지, 오디오 및 기타 데이터 형식을 포함한 다양한 소스에서 정보를 동시에 이해하고 처리하는 모델의 능력을 의미합니다. Spring AI Message API는 멀티모달 LLM을 지원하기 위해 필요한 모든 추상화를 제공합니다. UserMessage의 content 필드는 주로 텍스트 입력에 사용되며, 선택적인 media 필드를 사용하여 이미지, 오디오 및 비디오와 같은 다른 모달리티의 추가 콘텐츠를 추가할 수 있습니다. MimeType은 모달리티 유형을 지정합니다. 사용된 LLM에 따라 Media data 필드는 Resource 객체로 된 원시 미디어 콘텐츠 또는 콘텐츠에 대한 URI일 수 있습니다. media 필드는 현재 사용자 입력 메시지(예: UserMessage)에만 적용됩니다. 시스템 메시지에는 의미가 없습니다. LLM 응답을 포함하는 AssistantMessage는 텍스트 콘텐츠만 제공합니다. 비텍스트 미디어 출력을 생성하려면 전용 단일 모달 모델 중 하나를 사용해야 합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/multimodality.html)"
"Spring AI에서 멀티모달리티를 지원하는 챗 모델은 무엇인가요?","Spring AI는 OpenAI (예: GPT-4 및 GPT-4o 모델), Ollama (예: LlaVa 및 Baklava 모델), Vertex AI Gemini (예: gemini-1.5-pro-001, gemini-1.5-flash-001 모델), Anthropic Claude 3, AWS Bedrock Anthropic Claude 3 및 Azure Open AI (예: GPT-4o 모델)의 멀티모달 지원을 제공합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/multimodality.html)"
"Spring AI에서 생성된 비텍스트 미디어 출력을 얻으려면 어떻게 해야 하나요?","Spring AI에서 생성된 비텍스트 미디어 출력을 얻으려면 전용 단일 모달 모델 중 하나를 사용해야 합니다. 이미지, 오디오 및 비디오와 같은 미디어 출력을 생성하는 데 사용할 수 있는 다양한 모델이 있습니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/multimodality.html)"
"Structured Output Converter는 어떤 목적으로 도입되었나요?","Structured Output Converter는 2024년 02월 05일 기준으로 이전의 OutputParser, BeanOutputParser, ListOutputParser, MapOutputParser 클래스를 대체하기 위해 도입되었습니다. 이는 주로 이름 변경과 함께 일부 개선된 기능을 제공하기 위한 것입니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/structured-output-converter.html)"
"StructuredOutputConverter 인터페이스는 어떤 기능을 제공하나요?","StructuredOutputConverter 인터페이스는 텍스트 기반 AI 모델 출력에서 Java 클래스 또는 값 배열과 같은 구조화된 출력을 얻을 수 있도록 합니다. 이 인터페이스는 Spring Converter<String, T> 인터페이스와 FormatProvider 인터페이스를 결합합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/structured-output-converter.html)"
"Spring AI에서 제공하는 Converter 구현체는 어떤 것들이 있나요?","Spring AI에서는 AbstractConversionServiceOutputConverter, AbstractMessageOutputConverter, BeanOutputConverter, MapOutputConverter, ListOutputConverter 등의 Converter 구현체를 제공합니다. 각각의 구현체는 특정한 형식의 구조화된 출력을 생성하는 데 사용됩니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/structured-output-converter.html)"
"ETL 파이프라인은 Retrieval Augmented Generation(RAG) 사용 사례에서 어떤 역할을 하나요?","ETL 파이프라인은 Retrieval Augmented Generation(RAG) 사용 사례에서 데이터 처리의 핵심 역할을 합니다. 이 파이프라인은 원시 데이터 소스에서 구조화된 벡터 저장소로 데이터를 흐르게 하여 AI 모델에 의해 검색될 수 있는 최적의 형식으로 데이터를 보장합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/etl-pipeline.html)"
"ETL 파이프라인에서 사용되는 주요 구성 요소는 무엇인가요?","ETL 파이프라인에는 DocumentReader, DocumentTransformer, DocumentWriter라는 세 가지 주요 구성 요소가 있습니다. DocumentReader는 다양한 소스에서 문서를 제공하는 소스를 제공합니다. DocumentTransformer는 처리 워크플로우의 일부로 문서 일괄 처리를 변환합니다. DocumentWriter는 ETL 프로세스의 마지막 단계를 관리하여 문서를 저장할 준비를 합니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/etl-pipeline.html)"
"ETL 파이프라인에서 사용되는 Document 클래스는 어떤 역할을 하나요?","Document 클래스는 텍스트, 메타데이터 및 선택적으로 이미지, 오디오 및 비디오와 같은 추가 미디어 유형을 포함합니다. 이 클래스는 PDF, 텍스트 파일 및 기타 문서 유형에서 DocumentReader를 통해 내용을 생성하는 데 사용됩니다. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/etl-pipeline.html)"
"인공지능 애플리케이션의 테스트에서 평가자의 역할은 무엇인가요?","평가자는 생성된 콘텐츠를 평가하여 인공지능 모델이 환각된 응답을 생성하지 않았는지 확인합니다. Evaluator 함수형 인터페이스를 사용하여 평가를 수행합니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/testing.html>)"
"Evaluator 인터페이스의 입력은 무엇인가요?","Evaluator 인터페이스의 입력은 EvaluationRequest 클래스로 정의되며, 사용자 텍스트, 문맥 데이터 및 AI 모델의 응답 내용을 포함합니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/testing.html>)"
"RelevancyEvaluator 구현은 무엇인가요?","RelevancyEvaluator는 인공지능 모델을 사용하여 응답을 평가하는 구현 중 하나입니다. RelevancyEvaluator는 입력(userText)과 인공지능 모델의 출력(chatResponse)을 사용하여 쿼리 응답이 문맥 정보와 일치하는지 평가합니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/testing.html>)"
"제네릭 모델 API의 목적은 무엇인가요?","모든 AI 모델에 대한 기반을 제공하기 위해, 제네릭 모델 API가 만들어졌습니다. 이를 통해 스프링 AI에 새로운 AI 모델 지원을 쉽게 기여할 수 있습니다. 이 API는 일반적인 패턴을 따르도록 설계되었습니다."
"Model 인터페이스는 무엇인가요? 어떤 역할을 하나요?","Model 인터페이스는 AI 모델을 호출하기 위한 일반적인 API를 제공합니다. 이 인터페이스는 다양한 유형의 AI 모델과의 상호작용을 처리하기 위해 요청을 보내고 응답을 받는 과정을 추상화합니다. 이 인터페이스는 Java 제네릭을 사용하여 다른 유형의 요청과 응답을 수용하므로, 다양한 AI 모델 구현에 대한 유연성과 적응성을 향상시킵니다."
"StreamingModel 인터페이스는 무엇인가요? 어떤 역할을 하나요?","StreamingModel 인터페이스는 스트리밍 응답을 가진 AI 모델을 호출하기 위한 일반적인 API를 제공합니다. 이 인터페이스는 요청을 보내고 스트리밍 응답을 받는 과정을 추상화합니다. 이 인터페이스는 Java 제네릭을 사용하여 다른 유형의 요청과 응답을 수용하므로, 다양한 AI 모델 구현에 대한 유연성과 적응성을 향상시킵니다."
"Spring AI에서 어떤 핵심 컴포넌트에 대한 관찰 기능을 제공하나요?","Spring AI는 ChatClient(Advisors 포함), ChatModel, EmbeddingModel, ImageModel 및 VectorStore의 핵심 컴포넌트에 대한 관찰 기능을 제공합니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/observability/index.html>)"
"OpenTelemetry에서 ChatClient 입력 데이터를 어떻게 처리할 수 있나요?","OpenTelemetry에서는 ChatClient 입력 데이터를 span events로 저장할 수 있습니다. 그러나 이 기능은 아직 Micrometer API를 통해 표면화되지 않았습니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/observability/index.html>)"
"Spring AI에서 어떤 AI 모델 제공업체의 ChatModel 및 EmbeddingModel 구현에 대한 관찰 기능을 지원하나요?","Spring AI는 현재 OpenAI, Ollama, Anthropic 및 Mistral의 ChatModel 및 EmbeddingModel 구현에 대한 관찰 기능을 지원합니다. (출처: <https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/observability/index.html>)"
"Spring AI에서 Docker Compose를 사용하여 모델 서비스 또는 벡터 스토어에 연결하려면 어떻게 해야 하나요?","Spring AI는 Docker Compose를 사용하여 모델 서비스 또는 벡터 스토어에 연결하기 위해 Spring Boot 자동 구성을 제공합니다. 이를 사용하려면 프로젝트의 Maven pom.xml 파일에 다음 종속성을 추가하십시오: <dependency> <groupId>org.springframework.ai</groupId> <artifactId>spring-ai-spring-boot-docker-compose</artifactId> </dependency> 또는 Gradle build.gradle 빌드 파일에 다음 종속성을 추가하십시오: dependencies { implementation 'org.springframework.ai:spring-ai-spring-boot-docker-compose' } Spring AI BOM을 빌드 파일에 추가하려면 종속성 관리(../getting-started.html#dependency-management) 섹션을 참조하십시오. (출처: {https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/docker-compose.html})"
"Spring AI의 spring-ai-spring-boot-docker-compose 모듈에서 어떤 서비스 연결 팩토리가 제공되나요?","spring-ai-spring-boot-docker-compose 모듈에서는 다음과 같은 서비스 연결 팩토리가 제공됩니다: ChromaConnectionDetails, OllamaConnectionDetails, OpenSearchConnectionDetails, QdrantConnectionDetails, TypesenseConnectionDetails, WeaviateConnectionDetails. 각 팩토리는 해당 컨테이너 이름과 일치하는 연결 세부 정보를 지정합니다. (출처: {https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/docker-compose.html})"
"Spring AI에서 Docker Compose를 사용한 서비스 연결에 Observability 및 Testcontainers를 어떻게 사용할 수 있나요?","Docker Compose를 사용한 서비스 연결에 Observability 및 Testcontainers를 사용하려면 Spring AI의 Observability(../observabilty/index.html) 및 Testcontainers(testcontainers.html) 섹션을 참조하십시오. (출처: {https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/docker-compose.html})"
"Testcontainers와 Spring AI에서 Spring Boot auto-configuration을 설정하기 위해 어떤 의존성을 Maven pom.xml 파일에 추가해야 하나요?","<dependency> <groupId>org.springframework.ai</groupId> <artifactId>spring-ai-spring-boot-testcontainers</artifactId> </dependency> (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/testcontainers.html)"
"spring-ai-spring-boot-testcontainers 모듈에서 어떤 서비스 연결 팩토리가 제공되나요?","ChromaConnectionDetails, MilvusServiceClientConnectionDetails, OllamaConnectionDetails, OpenSearchConnectionDetails, QdrantConnectionDetails, TypesenseConnectionDetails, WeaviateConnectionDetails (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/testcontainers.html)"
"spring-ai-spring-boot-testcontainers 모듈에서 Docker Compose와 Cloud Bindings를 설정하기 위해 어떤 문서를 참조해야 하나요?","Docker Compose(docker-compose.html)와 Cloud Bindings(cloud-bindings.html) 섹션을 참조하세요. (출처: https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/api/testcontainers.html)"
"Spring AI에서 클라우드 바인딩을 지원하는 Spring Cloud Bindings의 기반은 무엇인가요?","spring-cloud-bindings(https://github.com/spring-cloud/spring-cloud-bindings)"
"Spring AI에서 클라우드 바인딩을 사용하려면 어떤 의존성을 포함해야 하나요?","<dependency> <groupId>org.springframework.ai</groupId> <artifactId>spring-ai-spring-cloud-bindings</artifactId> </dependency>"
"Chroma Vector Store의 경우 Spring AI에서 클라우드 바인딩을 사용하려면 어떤 속성을 지정해야 하나요?","uri, username, password (spring.ai.vectorstore.chroma.client.host, spring.ai.vectorstore.chroma.client.port, spring.ai.vectorstore.chroma.client.username, spring.ai.vectorstore.chroma.client.password)"
"PR을 제출하기 전에 어떤 명령어를 실행해야 하나요?","PR을 제출하기 전에 ./mvnw spring-javaformat:apply javadoc:javadoc -Pjavadoc 명령어를 실행해야 합니다. (출처: {https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/contribution-guidelines.html})"
"새로운 AI 모델 구현을 기여하려면 어떤 단계를 따라야 하나요?","새로운 AI 모델 구현을 기여하려면 Low-Level Client API 클래스를 생성하고, Model 구현을 만들고, Auto-Configuration 및 Spring Boot Starter를 구현하고, 테스트를 작성하고, 기여를 문서화해야 합니다. (출처: {https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/contribution-guidelines.html})"
"기존의 요청 및 응답 클래스를 사용할 수 없는 경우 어떻게 해야 하나요?","기존의 요청 및 응답 클래스를 사용할 수 없는 경우 Generic Model API를 위한 새로운 클래스를 생성하고 새로운 Java 패키지를 설정해야 합니다. (출처: {https://docs.spring.io/spring-ai/reference/1.0-SNAPSHOT/contribution-guidelines.html})"
